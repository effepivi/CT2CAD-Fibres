{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of fast realistic simulations on GPU to extract CAD models from microtomographic data in the presence of strong CT artefacts:\n",
    "\n",
    "## Registration of Tungsten Fibres on XCT Images\n",
    "\n",
    "### by Franck P. Vidal, Iwan T. Mitchell and Jean-Michel L&eacute;tang\n",
    "\n",
    "This demo aims to demonstrate how to register polygon meshes onto X-ray microtomography (micro-CT) scans of a tungsten fibre. The code relies on two building blocks:\n",
    "\n",
    "1.  A global optimisation algorithm. We use the [CMA-ES (Covariance Matrix Adaptation Evolution Strategy)](http://cma.gforge.inria.fr/http://cma.gforge.inria.fr/). It is an evolutionary algorithm for difficult non-linear non-convex optimisation problems.\n",
    "2.  A fast X-ray simulation toolkit. We use [gVirtualXRay](http://gvirtualxray.sourceforge.net/). It is a framework supporting many modern programming languages to generate realistic X-ray images from polygon meshes (triangles or tetrahedrons) on the graphics processor unit (GPU).\n",
    "\n",
    "Below is an example of CT slice from an experiment we carried out at the [European Synchrotron Radiation Facility (ESRF)](https://www.esrf.fr/https://www.esrf.fr/).\n",
    " \n",
    "![The fibre.](./scanned_object.png)\n",
    "\n",
    "In a previous article, on [*Investigation of artefact sources in synchrotron microtomography via virtual X-ray imaging*](https://doi.org/10.1016/j.nimb.2005.02.003) in [Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms](https://www.sciencedirect.com/journal/nuclear-instruments-and-methods-in-physics-research-section-b-beam-interactions-with-materials-and-atoms), we demonstrated that the image above was corrupted by:\n",
    "\n",
    "1) beam hardening depsite the use of a monochromator,\n",
    "2) the response of the camera despite the point spread function (PSF) being almost a Dirac, and\n",
    "3) phase contrast.\n",
    "\n",
    "That study was published in 2005, when computer were still relatively slow. Since then, massively parallel processors such as graphics processor units (GPUs) have emerged. Using today's hardware, we will demonstrate that we can now finely tuned the virtual experiments by mathematical optimisation to register polygons meshes on XCT data. Our simulations will include beam-hardening due to polychromatism, take into account the response of the detector, and have phase contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration steps\n",
    "\n",
    "![Main steps of the registration pipeline.](./pipeline.png)\n",
    "\n",
    "1. Initialisation\n",
    "    - [Import Python packages](#Import-packages)\n",
    "    - [Global variables](#Global-variables) with values corresponding to known parameters\n",
    "    - [Load the image data from the experiment at ESRF](#Load-the-image-data)\n",
    "    - [Recontruct the corresponding CT data](#CT-Reconstruction)\n",
    "    - [Normalise the image data](#Normalise-the-image-data)\n",
    "    - [Set the X-ray simulation environment](#Set-the-X-ray-simulation-environment)\n",
    "    - [LSF](#The-LSF)\n",
    "    - [Find circles to identify the centre of fibres](#Find-circles-to-identify-the-centre-of-fibres)\n",
    "2. [Simulate the CT acquisition](#Simulate-the-CT-acquisition)\n",
    "3. [Registration of the Ti90Al6V4 matrix](#Registration-of-a-cube)\n",
    "4. [Optimisation of the cores and fibres radii](#Optimisation-of-the-cores-and-fibres-radii)\n",
    "5. [Recentre each core/fibre](#Recentre-each-core/fibre)\n",
    "6. [Optimisation the radii after recentring](#Optimisation-the-radii-after-recentring)\n",
    "7. [Optimisation of the beam spectrum](#Optimisation-of-the-beam-spectrum)\n",
    "8. [Optimisation of the phase contrast and the radii](#Optimisation-of-the-phase-contrast-and-the-radii)\n",
    "9. [Optimisation of the phase contrast and the LSF](#Optimisation-of-the-phase-contrast-and-the-LSF)\n",
    "10. [Optimisation of the Poisson noise](#Optimisation-of-the-Poisson-noise)\n",
    "11. [Results in terms of linear attenuation coefficients](#Results-in-terms-of-linear-attenuation-coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image registration, a *moving object* is geometrically deformed so that its image matches a *target image*. \n",
    "The parameters of the deformation is controlled and iteratively tuned by an optimisation algorithm. \n",
    "\n",
    "![Registration flowchart](./registration.png)\n",
    "\n",
    "In our context, the target is the sinogram provided by the experiment at ESRF. \n",
    "The moving image is created by simulation using the CAD models and [gVirtualXRay](https://sourceforge.net/projects/gvirtualxray/). \n",
    "The simulation parameters controlling the CAD models are repetitively tuned by a global optimisation algorithm until a stopping criterion is met. \n",
    "The optimisation algorithm will minimise (or maximise) a numerical value, the *objective function*. \n",
    "The comparison between the target and moving images measures how different (or similar) the two images are. \n",
    "It is performed within the objective function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We need to import a few libraries (called packages in Python). We use:\n",
    " \n",
    "- `copy`: duplicating images using deepcopies;\n",
    "- `glob`: retrieving file names in a directory;\n",
    "- `math`: the `floor` function;\n",
    "- `os`: creating a new directory;\n",
    "- `sys`: retrieving the largest possible floating-point value;\n",
    "- `cma`: non-linear numerical optimization ([CMA-ES, Covariance Matrix Adaptation Evolution Strategy](https://github.com/CMA-ES/pycma));\n",
    "- ([OpenCV](https://www.opencv.org/)) (`cv2`): Hough transform and bilateral filter (an edge-preserving smoothing filter);\n",
    "- `imageio`: creating GIF files;\n",
    "- `IPython.display`: display Pandas'dataframes as HTML tables;\n",
    "- `matplotlib`: plotting data;\n",
    "- `mpl_toolkits`: plotting 3D data (final CAD models);\n",
    "- `numpy`: who doesn't use numpy?\n",
    "- `pandas`: creating a DataFrame to store $\\mu$ data;\n",
    "- [SimpleITK](https://simpleitk.org/): image processing and saving volume data;\n",
    "- `tomopy`: package for CT reconstruction;\n",
    "- `scipy`: for the convolution of a 2D image by a 1D kernel;\n",
    "- `skimage`: comparing the reference CT slice and the simulated one;\n",
    "- `sklearn`: comparing the reference CT slice and the simulated one;\n",
    "- `stl`: to import STL files (CAD models);\n",
    "- `lsf`: the line spread function to filter the X-ray images; and\n",
    "- `gvxrPython3`: [gVirtualXRay](http://gvirtualxray.sourceforge.net/)'s Python wrapper to simulate X-ray images using the Beer-Lambert law on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cma\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import tomopy\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy import ndimage\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.util import compare_images\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from stl import mesh\n",
    "\n",
    "plt.ioff()\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "# plt.rcParams['font.size'] = 15\n",
    "\n",
    "import gvxrPython3 as gvxr\n",
    "\n",
    "from lsf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\");\n",
    "\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.makedirs(\"plots\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables\n",
    "\n",
    "We need some global variables:\n",
    "\n",
    "-  `NoneType`: the type of `None`;\n",
    "-  `pixel_spacing_in_micrometre`: the physical distance between the centre of two successive pixel;\n",
    "-  `pixel_spacing_in_mm`: the physical distance between the centre of two successive pixel;\n",
    "-  `number_of_projections`: the total number of angles in the sinogram;he total number of angles in the sinogram;\n",
    "-  `angular_span_in_degrees`: the angular span covered by the sinogram;\n",
    "-  `angular_step`: the angular step;\n",
    "-  `theta`: the rotation angles in degrees (vertical axis of the sinogram);\n",
    "-  `theta_rad`: the rotation angles in radians (vertical axis of the sinogram);\n",
    "-  `roi_length`: control the size of the ROI when displayng the central fibre;\n",
    "-  `value_range`: control the binning of the Laplacian kernel\n",
    "-  `num_samples`: control the binning of the Laplacian kernel\n",
    "-  `sigma_set`: spread of the Laplacian kernels\n",
    "-  `k_set`: weight of the Laplacian kernels\n",
    "-  `label_set`: label of the structures on which a Laplacian kernel is applied\n",
    "-  `bias`: control the bias of the Poisson noise\n",
    "-  `gain`: control the gain of the Poisson noise: control the bias of the Poisson noise\n",
    "-  `scale`: control the scale of the Poisson noise: control the bias of the Poisson noise\n",
    "-  `use_normalisation`: use or do not use zero-mean, unit-variance normalisation in the objective functions;\n",
    "-  `use_sinogram`: compute the objective functions on the sinogram or flat-field;\n",
    "-  `metrics_type`: type of image comparison used in the objective functions;\n",
    "-  `fibre_radius`: radius of the SiC fibres in um\n",
    "-  `core_radius`: radius of the W fibres in um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoneType = type(None);\n",
    "pixel_spacing_in_micrometre = 1.9;\n",
    "pixel_spacing_in_mm = pixel_spacing_in_micrometre * 1e-3;\n",
    "number_of_projections = 900;\n",
    "angular_span_in_degrees = 180.0;\n",
    "angular_step = angular_span_in_degrees / number_of_projections;\n",
    "theta = np.linspace(0.,\n",
    "                    angular_span_in_degrees,\n",
    "                    number_of_projections,\n",
    "                    endpoint=False);\n",
    "theta_rad = theta / 180.0 * math.pi;\n",
    "\n",
    "roi_length = 60;\n",
    "\n",
    "value_range = 6;\n",
    "num_samples = 15;\n",
    "\n",
    "sigma_set = None;\n",
    "k_set = None;\n",
    "label_set = None;\n",
    "\n",
    "bias = None;\n",
    "gain = None;\n",
    "scale = None;\n",
    "\n",
    "use_normalisation = True;\n",
    "use_sinogram = True;\n",
    "\n",
    "metrics_type = \"RMSE\";\n",
    "\n",
    "fibre_radius = 140 / 2;  # um\n",
    "core_radius = 30 / 2;  # um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the image data\n",
    "\n",
    "Load and display the reference projections from a raw binary file, i.e. the target of the registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target of the registration\n",
    "reference_normalised_projections = np.fromfile(\"sino.raw\", dtype=np.float32);\n",
    "reference_normalised_projections.shape = [\n",
    "    number_of_projections,\n",
    "    int(reference_normalised_projections.shape[0] / number_of_projections)\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to save raw images in the MHA format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMHA(fname, image, spacing):\n",
    "    \"\"\"\n",
    "    save the image into a file.\n",
    "\n",
    "    :param str fname: the filename\n",
    "    :param 2D_image image: the image to save\n",
    "    :param [flt, flt, flt] spacing: the space between two successive voxels along the 3 direction\n",
    "    \"\"\"\n",
    "\n",
    "    volume = sitk.GetImageFromArray(image);\n",
    "    volume.SetSpacing(spacing);\n",
    "    sitk.WriteImage(volume, fname, useCompression=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference projections in a MHA file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA('outputs/reference_normalised_projections.mha', reference_normalised_projections, [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the reference projections using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [theta[0], theta[reference_normalised_projections.shape[0] // 2], theta[-1]];\n",
    "tics = [\n",
    "    0,\n",
    "    reference_normalised_projections.shape[0] // 2,\n",
    "    reference_normalised_projections.shape[0]-1\n",
    "];\n",
    "fig = plt.figure();\n",
    "imgplot = plt.imshow(reference_normalised_projections, cmap=\"gray\");\n",
    "plt.xlabel(\"Displacement of projection\");\n",
    "plt.ylabel(\"Angle of projection (in degrees)\");\n",
    "plt.yticks(tics, labels);\n",
    "plt.title(\"Projections after flat-field correction from the experiment at ESRF\");\n",
    "fig.colorbar(imgplot);\n",
    "plt.savefig('plots/Normalised_projections_from_experiment_ESRF.pdf')\n",
    "plt.savefig('plots/Normalised_projections_from_experiment_ESRF.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the literature, a projection is often modelled using the polychromatic version of the Beer-Lambert law:\n",
    "$$\\mathbf{I}(x,y) = \\sum_i \\mathbf{R}_i \\, \\mathbf{N}_i \\; \\exp\\left({-\\sum_j \\mu_j(E_i) \\; \\mathbf{d}_j(x,y)}\\right)$$\n",
    "\n",
    "- $\\mathbf{I}(x,y)$ the value of the raw X-ray projection at pixel location $(x,y)$, and with the sample and with the X-ray beam turned on;\n",
    "- $i$ the $i$-th energy channel in the beam spectrum;   \n",
    "- $E_i$ the energy in eV; \n",
    "- $\\mathbf{R}_i$ and $\\mathbf{N}_i$ the detector response and the number of photons at that energy respectively;\n",
    "- $j$ the $j$-th material being scanned, $\\mu_j(E_i)$ its linear attenuation coefficient at energy $E_i$, and\n",
    "- $\\mathbf{d}_j(x,y)$ path length in cm$^{-1}$ of the ray crossing the $j$-th material from the X-ray source to pixel $(x,y)$.\n",
    "\n",
    "\n",
    "Projections are then corrected to account for variations in beam homogeneity and in the pixel-to-pixel sensitivity of the detector. This is the projection with flat-field correction ($\\mathbf{Proj}$):\n",
    "$$\\mathbf{Proj} = \\frac{\\mathbf{I} - \\mathbf{D}}{\\mathbf{F} - \\mathbf{D}}$$\n",
    "$\\mathbf{F}$ (full fields) and $\\mathbf{D}$ (dark fields) are projection images without sample and acquired with and without the X-ray beam turned on respectively. Note that with an ideal detector ($\\mathbf{R}_i=E_i$), pixels of $\\mathbf{D}$ are null, and pixels of $\\mathbf{F}$ are equal to $\\sum_i E_i \\; \\mathbf{N}_i$. \n",
    "\n",
    "![Projections after flat-field correction from the experiment at ESRF](plots/Normalised_projections_from_experiment_ESRF.png)\n",
    "\n",
    "`reference_normalised_projections` (the figure above) corresponds to the data loaded from the binary file. It corresponds to $\\mathbf{Proj}$, i.e. the flat-field correction has already been performed. \n",
    "\n",
    "We can see that when the primary spectrum is not monochromatic the measurement is the sum of several attenuation laws. We could however compute the effective monochromatic attenuation that would give the same measurement:\n",
    "$$    \\mathbf{I}(x,y) = \\mathbf{I}_0(x,y) \\; \\exp\\left({-\\sum_j \\mu_j(E_{\\mathrm{eff}}) \\; \\mathbf{d}_j(x,y)}\\right)$$\n",
    "    \n",
    "with $\\mathbf{I}_0(x,y) = \\sum_i \\mathbf{R}_i \\, \\mathbf{N}_i$, and where $E_{\\mathrm{eff}}$ corresponds to the monochromatic energy that would give the same attenuation than\n",
    "the one measured. We are now able to linearise the transmission tomography data, namely $\\mathbf{Proj}$, and we get the sinogram:\n",
    "$$\\textbf{Sino}=-\\ln\\left(\\textbf{Proj}\\right)$$\n",
    "\n",
    "We define a new function to compute the sinogram from flat-field correction and calls it straightaway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSinogramFromFlatField(normalised_projections):\n",
    "    \"\"\"\n",
    "    This function apply the minus log normalisation\n",
    "    on the projections that bave been corrected with the flat-field method.\n",
    "\n",
    "    :param 2D_image normalised_projections: The projections after flat-field corrections\n",
    "    :return the sinogram.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a temporary image to hold the sinogram\n",
    "    simulated_sinogram = copy.deepcopy(normalised_projections);\n",
    "\n",
    "    # Make sure no value is negative or null (because of the log function)\n",
    "    # It should not be the case, however, when the Laplacian is used to simulate\n",
    "    # phase contrast, negative values can be generated.\n",
    "    threshold = 0.000001\n",
    "    simulated_sinogram[simulated_sinogram < threshold] = threshold;\n",
    "\n",
    "    # Apply the minus log normalisation\n",
    "    simulated_sinogram = -np.log(simulated_sinogram);\n",
    "\n",
    "    # Rescale the data taking into account the pixel size\n",
    "    simulated_sinogram /= pixel_spacing_in_micrometre * gvxr.getUnitOfLength(\"um\") / gvxr.getUnitOfLength(\"cm\");\n",
    "\n",
    "    # Return the new image\n",
    "    return simulated_sinogram;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sinogram from the flat-field data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sinogram = computeSinogramFromFlatField(reference_normalised_projections);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA('outputs/reference_sinogram.mha', reference_sinogram, [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the sinogram using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[theta[0], theta[reference_sinogram.shape[0] // 2], theta[-1]];\n",
    "tics=[0, reference_sinogram.shape[0] // 2, reference_sinogram.shape[0]-1];\n",
    "fig=plt.figure();\n",
    "imgplot = plt.imshow(reference_sinogram, cmap=\"gray\");\n",
    "plt.xlabel(\"Displacement of projection\");\n",
    "plt.ylabel(\"Angle of projection (in degrees)\");\n",
    "plt.yticks(tics, labels);\n",
    "plt.title(\"Sinogram of the reference image\");\n",
    "fig.colorbar(imgplot);\n",
    "plt.savefig('plots/Sinogram_reference_image.pdf');\n",
    "plt.savefig('plots/Sinogram_reference_image.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sinogram of the reference image](./plots/Sinogram_reference_image.png)\n",
    "\n",
    "## CT reconstruction\n",
    "\n",
    "Now we got a sinogram, we can reconstruct the CT slice. As we used a synchrotron, we can assume we have a parallel source. It means we can use a FBP rather than the FDK algorithm. In fact we use the gridrec algorithm, which is much faster:\n",
    "\n",
    "Dowd BA, Campbell GH, Marr RB, Nagarkar VV, Tipnis SV, Axe L, and Siddons DP. [Developments in synchrotron x-ray computed microtomography at the national synchrotron light source](https://doi.org/10.1117/12.363725). In Proc. SPIE, volume 3772, 224–236. 1999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sinogram.shape = [\n",
    "    reference_sinogram.shape[0],\n",
    "    1,\n",
    "    reference_sinogram.shape[1]\n",
    "];\n",
    "\n",
    "rot_center = int(reference_sinogram.shape[2]/2);\n",
    "\n",
    "reference_CT = tomopy.recon(reference_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp')[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the reconstruction in a MHA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA('outputs/reference_CT.mha', reference_CT, [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the CT slice using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure();\n",
    "norm = cm.colors.Normalize(vmax=30, vmin=-20)\n",
    "imgplot = plt.imshow(reference_CT, cmap=\"gray\", norm=norm);\n",
    "fig.colorbar(imgplot);\n",
    "plt.title(\"Reference image (in linear attenuation coefficients, cm$^{-1}$)\");\n",
    "plt.savefig('plots/reference_image_in_mu.pdf');\n",
    "plt.savefig('plots/reference_image_in_mu.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Reference image (in linear attenuation coefficients](./plots/reference_image_in_mu.png)\n",
    "\n",
    "## Normalise the image data\n",
    "\n",
    "Zero-mean, unit-variance normalisation is applied to use the reference images in objective functions and perform the registration. Note that it is called standardisation (or Z-score Normalisation) in machine learning. It is computed as follows:\n",
    "\n",
    "$$\\mathbf{m}_o=\\frac{\\mathbf{m}-\\bar{m}}{\\sigma_m}$$\n",
    "\n",
    "where $\\mathbf{m}_o$ is the image after normalisation of Image $\\mathbf{m}$, $\\bar{m}$ is the average pixel value of Image $\\mathbf{m}$, and $\\sigma_m$ its standard deviation.\n",
    "After normalisation, the average pixel value is null and the standard deviation of pixel values is equal to one.\n",
    "\n",
    "We define a function to apply this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardisation(I):\n",
    "    image = copy.deepcopy(I);\n",
    "\n",
    "    # Sometimes the CT reconstruction algorithm create NaN on\n",
    "    # the top and right borders, we filter them out using\n",
    "    # a median filter ignoring NaN\n",
    "    nan_index = np.argwhere(np.isnan(image));\n",
    "    if nan_index.shape[0]:\n",
    "        temp = np.pad(image, 1, \"edge\");\n",
    "\n",
    "        for index in nan_index:\n",
    "            roi = temp[index[0]-1+1:index[0]+1+2, index[1]-1+1:index[1]+1+2];\n",
    "            image[index[0], index[1]] = np.nanmedian(roi);\n",
    "\n",
    "    return (image - image.mean()) / image.std();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the reference sinogram and CT slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalised_reference_sinogram = standardisation(reference_sinogram);\n",
    "normalised_reference_CT       = standardisation(reference_CT);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the X-ray simulation environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an OpenGL context, here using EGL, i.e. no window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvxr.createWindow(0, 1, \"EGL\");\n",
    "gvxr.setWindowSize(512, 512);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameters of the X-ray detector (flat pannel), e.g. number of pixels, pixel, spacing, position and orientation:\n",
    "\n",
    "![3D scene to be simulated using gVirtualXray](./3d_scene.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_width_in_pixels = reference_sinogram.shape[2];\n",
    "detector_height_in_pixels = 1;\n",
    "distance_object_detector_in_m =    0.08; # = 80 mm\n",
    "\n",
    "gvxr.setDetectorPosition(-distance_object_detector_in_m, 0.0, 0.0, \"m\");\n",
    "gvxr.setDetectorUpVector(0, 1, 0);\n",
    "gvxr.setDetectorNumberOfPixels(detector_width_in_pixels, detector_height_in_pixels);\n",
    "gvxr.setDetectorPixelSize(pixel_spacing_in_micrometre, pixel_spacing_in_micrometre, \"micrometer\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the source parameters (beam shape, source position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the beam\n",
    "distance_source_detector_in_m  = 145.0;\n",
    "\n",
    "gvxr.setSourcePosition(distance_source_detector_in_m - distance_object_detector_in_m,  0.0, 0.0, \"m\");\n",
    "gvxr.usePointSource();\n",
    "# gvxr.useParallelBeam();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beam spectrum. Here we have a polychromatic beam, with 97% of the photons at 33 keV, 2% at 66 keV and 1% at 99 keV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_spectrum = [(33, 0.97, \"keV\"), (66, 0.02, \"keV\"), (99, 0.01, \"keV\")];\n",
    "\n",
    "for energy, percentage, unit in energy_spectrum:\n",
    "    gvxr.addEnergyBinToSpectrum(energy, unit, percentage);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the beam spectrum using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_in_keV = [];\n",
    "weights = [];\n",
    "\n",
    "for energy, percentage, unit in energy_spectrum:\n",
    "    weights.append(percentage);\n",
    "    energies_in_keV.append(energy * gvxr.getUnitOfEnergy(unit) / gvxr.getUnitOfEnergy(\"keV\"));\n",
    "\n",
    "fig=plt.figure();\n",
    "plt.xlabel(\"Energy bin (in keV)\");\n",
    "plt.ylabel(\"Relative weight\");\n",
    "plt.xticks(energies_in_keV);\n",
    "plt.yticks(weights);\n",
    "plt.title(\"Incident beam spectrum\");\n",
    "plt.bar(energies_in_keV, weights);\n",
    "plt.savefig('plots/beam_spectrum.pdf');\n",
    "plt.savefig('plots/beam_spectrum.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incident beam spectrum](plots/beam_spectrum.png)\n",
    "\n",
    "The material properties (chemical composition and density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibre_material = [(\"Si\", 0.5), (\"C\", 0.5)];\n",
    "fibre_density = 3.2; # g/cm3\n",
    "\n",
    "core_radius = 30 / 2; # um\n",
    "core_material = [(\"W\", 1)];\n",
    "\n",
    "g_matrix_width = 0;\n",
    "g_matrix_height = 0;\n",
    "g_matrix_x = 0;\n",
    "g_matrix_y = 0;\n",
    "matrix_material = [(\"Ti\", 0.9), (\"Al\", 0.06), (\"V\", 0.04)];\n",
    "matrix_density = 4.42 # g/cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LSF\n",
    "\n",
    "In a previous study, we experimentally measured the impulse response of the detector as the line spread function (LSF):\n",
    "\n",
    "F.P. Vidal, J.M. Létang, G. Peix, P. Cloetens, Investigation of artefact sources in synchrotron microtomography via virtual X-ray imaging, *Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms*, Volume 234, Issue 3, 2005, Pages 333-348, ISSN 0168-583X, DOI [10.1016/j.nimb.2005.02.003](10.1016/j.nimb.2005.02.003).\n",
    "\n",
    "We use this model during the initial steps of the registration. The LSF model will be tuned in one of the final steps of the registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(-20., 21., 1.);\n",
    "lsf_kernel=lsf(t*41)/lsf(0);\n",
    "lsf_kernel/=lsf_kernel.sum();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the LSF using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure();\n",
    "plt.title(\"Response of the detector (LSF)\");\n",
    "plt.plot(t, lsf_kernel);\n",
    "plt.savefig('plots/LSF.pdf');\n",
    "plt.savefig('plots/LSF.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Response of the detector (LSF)](plots/LSF.png)\n",
    "\n",
    "## Find circles to identify the centre of fibres\n",
    "\n",
    "We can use the Hoguh transform to detect where circles are in the image. However, the input image in OpenCV's function must be in UINT. We blur it using a bilateral filter (an edge-preserving smoothing filter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert the image to UINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We first create a function to convert images in floating point numbers into UINT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def float2uint8(anImage, min_threshold = None, max_threshold = None):\n",
    "    \n",
    "    uchar_image = copy.deepcopy(anImage);\n",
    "\n",
    "    if isinstance(min_threshold, NoneType):\n",
    "        min_threshold = np.min(uchar_image);\n",
    "\n",
    "    if isinstance(max_threshold, NoneType):\n",
    "        max_threshold = np.max(uchar_image);\n",
    "        \n",
    "    uchar_image[uchar_image < min_threshold] = min_threshold;\n",
    "    uchar_image[uchar_image > max_threshold] = max_threshold;\n",
    "\n",
    "    uchar_image -= min_threshold;\n",
    "    uchar_image /= max_threshold - min_threshold;\n",
    "    uchar_image *= 255;\n",
    "    \n",
    "    return uchar_image.astype(np.uint8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We blur the CT scan using a bilateral filter. It preserves edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uint8_reference_CT = float2uint8(reference_CT, 0, 300);\n",
    "blurred_reference_CT = cv2.bilateralFilter(uint8_reference_CT, 9, 75, 75);\n",
    "\n",
    "saveMHA('outputs/blurred_reference_CT.mha', blurred_reference_CT, [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply the Hough transform\n",
    "\n",
    "As the fibres and the cores correspond to circles in the CT images, the obvious technique to try is the Hough Circle Transform (HCT). It is a feature extraction technique used in image analysis that can output a list of circles (centres and radii). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles(blurred_reference_CT, cv2.HOUGH_GRADIENT, 2, 80,\n",
    "                            param1=150, param2=5, minRadius=5, maxRadius=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Overlay the detected circles on the top of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cimg = cv2.cvtColor(float2uint8(reference_CT, 0, 50), cv2.COLOR_GRAY2BGR);\n",
    "circles = np.uint16(np.around(circles));\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    \n",
    "    # draw the outer circle\n",
    "    cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2);\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(cimg, (i[0], i[1]), 2, (0, 0, 255), 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig=plt.figure();\n",
    "imgplot = plt.imshow(cimg);\n",
    "plt.title(\"Reference image and detected Tungsten cores\");\n",
    "plt.savefig('plots/fibre_detection_using_Hough_transform.pdf');\n",
    "plt.savefig('plots/fibre_detection_using_Hough_transform.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Reference image and detected Tungsten cores using the Hough Circle Transform](./plots/fibre_detection_using_Hough_transform.png)\n",
    "\n",
    "13 fibres were missed and many centres were misplaced. Controlling the meta-parameters of the algorithm can be difficult to employ in a fully-automatic registration framework. We will use another technique to register the fibres, the popular Otsu's method. It creates a histogram and uses a heuristic to determine a threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the numpy array in float32 into uint, then into a SITK image\n",
    "volume = sitk.GetImageFromArray(blurred_reference_CT);\n",
    "volume.SetSpacing([pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "# Apply the Otsu's method\n",
    "otsu_filter = sitk.OtsuThresholdImageFilter();\n",
    "otsu_filter.SetInsideValue(0);\n",
    "otsu_filter.SetOutsideValue(1);\n",
    "seg = otsu_filter.Execute(volume);\n",
    "\n",
    "# Print the corresponding threshold\n",
    "print(\"Threshold:\", otsu_filter.GetThreshold());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sitk.WriteImage(seg, \"outputs/cores_segmentation.mha\", useCompression=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure();\n",
    "\n",
    "volume = sitk.GetImageFromArray(float2uint8(reference_CT, 0, 50));\n",
    "volume.SetSpacing([pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "imgplot = plt.imshow(sitk.GetArrayViewFromImage(sitk.LabelOverlay(volume, seg)));\n",
    "plt.title(\"Reference image and detected Tungsten cores\");\n",
    "plt.savefig('plots/fibre_detection_using_otsu_method.pdf');\n",
    "plt.savefig('plots/fibre_detection_using_otsu_method.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Reference image and detected Tungsten cores using the Otsu's method](./plots/fibre_detection_using_otsu_method.png)\n",
    "\n",
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean-up using mathematical morphology\n",
    "cleaned_thresh_img = sitk.BinaryOpeningByReconstruction(seg, [3, 3, 3])\n",
    "cleaned_thresh_img = sitk.BinaryClosingByReconstruction(cleaned_thresh_img, [3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sitk.WriteImage(cleaned_thresh_img, \"outputs/cores_cleaned_segmentation.mha\", useCompression=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure();\n",
    "\n",
    "volume = sitk.GetImageFromArray(float2uint8(reference_CT, 0, 50));\n",
    "volume.SetSpacing([pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "imgplot = plt.imshow(sitk.GetArrayViewFromImage(sitk.LabelOverlay(volume, cleaned_thresh_img)));\n",
    "plt.title(\"Reference image and detected Tungsten cores\");\n",
    "plt.savefig('plots/fibre_detection_using_otsu_method_after_cleaning.pdf');\n",
    "plt.savefig('plots/fibre_detection_using_otsu_method_after_cleaning.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Reference image and detected Tungsten cores using the Otsu's method after mathematical morphology](plots/fibre_detection_using_otsu_method_after_cleaning.png)\n",
    "\n",
    "## Mark each potential tungsten corewith unique label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each distinct tungsten core is assigned a unique label, i.e. a unique pixel intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_labels = sitk.ConnectedComponent(cleaned_thresh_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure();\n",
    "\n",
    "volume = sitk.GetImageFromArray(float2uint8(reference_CT, 0, 50));\n",
    "volume.SetSpacing([pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "imgplot = plt.imshow(sitk.GetArrayViewFromImage(sitk.LabelOverlay(volume, core_labels)));\n",
    "plt.title(\"Cleaned Binary Segmentation of the Tungsten cores\");\n",
    "plt.savefig('plots/fibre_detection_with_label_overlay.pdf');\n",
    "plt.savefig('plots/fibre_detection_with_label_overlay.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Reference image and labelled detected Tungsten cores](plots/fibre_detection_with_label_overlay.png)\n",
    "\n",
    "\n",
    "### Object Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once we have the segmented objects we look at their shapes and the intensity distributions inside the objects. For each labelled tungsten core, we extract the centroid. Note that sizes and positions are given in millimetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_stats = sitk.LabelShapeStatisticsImageFilter()\n",
    "shape_stats.ComputeOrientedBoundingBoxOn()\n",
    "shape_stats.Execute(core_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroid_set = [];\n",
    "\n",
    "for i in shape_stats.GetLabels():\n",
    "    centroid_set.append(cleaned_thresh_img.TransformPhysicalPointToIndex(shape_stats.GetCentroid(i)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of the centres of all the fibres that can be used as a parameter of the function below to create the cylinders corresponding to the cores and the fibres. \n",
    "For each core, a cylinder is creatd and translated:\n",
    "```python\n",
    "        gvxr.emptyMesh(\"core_\"  + str(i));\n",
    "        gvxr.makeCylinder(\"core_\"  + str(i), number_of_sectors, 815.0,  core_radius, \"micrometer\");\n",
    "        gvxr.translateNode(\"core_\"  + str(i), y, 0.0, x, \"micrometer\");\n",
    "```\n",
    "For each fibre, another cylinder is created and translated:\n",
    "```python\n",
    "        gvxr.emptyMesh(\"fibre_\"  + str(i));\n",
    "        gvxr.makeCylinder(\"fibre_\"  + str(i), number_of_sectors, 815.0,  fibre_radius, \"micrometer\");\n",
    "        gvxr.translateNode(\"fibre_\"  + str(i), y, 0.0, x, \"micrometer\");\n",
    "```\n",
    "The fibre's cylinder is hollowed to make space for its core:\n",
    "```python\n",
    "        gvxr.subtractMesh(\"fibre_\" + str(i), \"core_\" + str(i));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setFibres(aCentroidSet):\n",
    "    \"\"\"This function loads a cylinders in the GPU memory.\n",
    "    Some are hollow and represent the fibres, some are not and\n",
    "    correspond to the cores.\n",
    "\n",
    "    :param array aCentroidSet: a list of cylinder centres.\n",
    "    \"\"\"\n",
    "\n",
    "    global core_radius;\n",
    "    global fibre_radius;\n",
    "\n",
    "    # Create empty geometries\n",
    "    gvxr.emptyMesh(\"fibre\");\n",
    "    gvxr.emptyMesh(\"core\");\n",
    "\n",
    "    # Number of sectors to approximate cylinders with triangle meshes\n",
    "    # It controls the accuracy of the meshes.\n",
    "    number_of_sectors = 100;\n",
    "\n",
    "    # Process all the centres from the input list\n",
    "    for i, cyl in enumerate(aCentroidSet):\n",
    "\n",
    "        # Convert the centre position from 2D image coordinates in 3D world coordinates\n",
    "        x = pixel_spacing_in_micrometre * -(cyl[0] - reference_CT.shape[1] / 2 + 0.5);\n",
    "        y = pixel_spacing_in_micrometre * (cyl[1] - reference_CT.shape[0] / 2 + 0.5);\n",
    "\n",
    "        # Create empty geometries (is it needed?)\n",
    "        gvxr.emptyMesh(\"fibre_\" + str(i));\n",
    "        gvxr.emptyMesh(\"core_\" + str(i));\n",
    "\n",
    "        # Create the two corresponding cylinders (fibre and core)\n",
    "        gvxr.makeCylinder(\"fibre_\" + str(i), number_of_sectors, 815.0, fibre_radius, \"micrometer\");\n",
    "        gvxr.makeCylinder(\"core_\"  + str(i), number_of_sectors, 815.0,  core_radius, \"micrometer\");\n",
    "\n",
    "        # Translate the two cylinders to the position of their centre\n",
    "        gvxr.translateNode(\"fibre_\" + str(i), y, 0.0, x, \"micrometer\");\n",
    "        gvxr.translateNode(\"core_\" + str(i), y, 0.0, x, \"micrometer\");\n",
    "\n",
    "        # Apply the local transformation matrix (so that we could save the corresponding STL files)\n",
    "        gvxr.applyCurrentLocalTransformation(\"fibre_\" + str(i));\n",
    "        gvxr.applyCurrentLocalTransformation(\"core_\" + str(i));\n",
    "\n",
    "        # Subtract the fibre from the matrix\n",
    "        gvxr.subtractMesh(\"matrix\", \"fibre_\" + str(i));\n",
    "\n",
    "        # Subtract the core from the fibre\n",
    "        gvxr.subtractMesh(\"fibre_\" + str(i), \"core_\" + str(i));\n",
    "\n",
    "        # Save the corresponding STL files\n",
    "        # gvxr.saveSTLfile(\"fibre_\" + str(i), \"Tutorial2/outputs/fibre_\" + str(i) + \".stl\");\n",
    "        # gvxr.saveSTLfile(\"core_\" + str(i),  \"Tutorial2/outputs/core_\"  + str(i) + \".stl\");\n",
    "\n",
    "        # Add the mesh of the current fibre to the overall fibre mesh\n",
    "        gvxr.addMesh(\"fibre\", \"fibre_\" + str(i));\n",
    "\n",
    "        # Add the mesh of the current core to the overall core mesh\n",
    "        gvxr.addMesh(\"core\", \"core_\"  + str(i));\n",
    "\n",
    "    # Set the mesh colours (for the interactive visualisation)\n",
    "    gvxr.setColor(\"fibre\", 1.0, 0.0, 0.0, 1.0);\n",
    "    gvxr.setColor(\"core\",  1.0, 0.0, 1.0, 1.0);\n",
    "\n",
    "    # Set the fibre's material properties\n",
    "    # gvxr.setLinearAttenuationCoefficient(\"fibre\", fibre_mu, \"cm-1\");\n",
    "    gvxr.setCompound(\"fibre\", \"SiC\");\n",
    "    gvxr.setDensity(\"fibre\", fibre_density, \"g/cm3\");\n",
    "\n",
    "    # Set the core's material properties\n",
    "    # gvxr.setLinearAttenuationCoefficient(\"core\", core_mu, \"cm-1\");\n",
    "    gvxr.setElement(\"core\", \"W\");\n",
    "\n",
    "    # Add the fibres and cores to the X-ray renderer\n",
    "    gvxr.addPolygonMeshAsInnerSurface(\"core\");\n",
    "    gvxr.addPolygonMeshAsInnerSurface(\"fibre\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration of a cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to create the polygon mesh of the Ti90Al6V4 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setMatrix(apGeneSet):\n",
    "    \"\"\"This function loads a cube in the GPU memory. The cube represents\n",
    "    the Ti90Al6V4 matrix.\n",
    "\n",
    "    apGeneSet[0] is a number between -0.5 and 0.5, related to the translation vector (X component) of the cube. It can be interpreted as a percentage of the detector width.\n",
    "    apGeneSet[1] is the same as apGeneSet[0], but related to the Y component of the translation vector.\n",
    "    apGeneSet[2] is a number between -0.5 and 0.5, related to the rotation angle in degrees\n",
    "    apGeneSet[3] is a scaling factor between -0.5 and 0.5. It can be interpreted as a percentage of the detector width.\n",
    "    apGeneSet[4] is a scaling factor between -0.5 and 0.5. It can be interpreted as a percentage of apGeneSet[3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all the geometries from the whole scenegraph\n",
    "    gvxr.removePolygonMeshesFromSceneGraph();\n",
    "\n",
    "    # Make a cube\n",
    "    gvxr.makeCube(\"matrix\", 1.0, \"micrometer\");\n",
    "\n",
    "    # Translation vector\n",
    "    x = apGeneSet[0] * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "    y = apGeneSet[1] * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "    gvxr.translateNode(\"matrix\", x, 0.0, y, \"micrometer\");\n",
    "\n",
    "    # Rotation angle\n",
    "    rotation_angle_in_degrees = (apGeneSet[2] + 0.5) * 180.0;\n",
    "    gvxr.rotateNode(\"matrix\", rotation_angle_in_degrees, 0, 1, 0);\n",
    "\n",
    "    # Scaling factors\n",
    "    w = (apGeneSet[3] + 0.5) * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "    h = (apGeneSet[4] + 0.5) * w;\n",
    "    gvxr.scaleNode(\"matrix\", w, 815, h);\n",
    "\n",
    "    # Apply the transformation matrix so that we can save the corresponding STL file\n",
    "    gvxr.applyCurrentLocalTransformation(\"matrix\");\n",
    "\n",
    "    # Set the matrix's material properties\n",
    "    gvxr.setMixture(\"matrix\", \"Ti90Al6V4\");\n",
    "    gvxr.setDensity(\"matrix\", matrix_density, \"g/cm3\");\n",
    "\n",
    "    # Add the matrix to the X-ray renderer\n",
    "    gvxr.addPolygonMeshAsInnerSurface(\"matrix\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the CT acquisition\n",
    "\n",
    "There are 7 successive steps to simulate the XCT data acquisition:\n",
    "\n",
    "1. Set the fibre and cores geometries and material properties (Step 39)\n",
    "2. Set the matrix geometry and material properties (Step 40)\n",
    "3. Simulate the raw projections for each angle:\n",
    "   - Without phase contrast (Line 5 of Step 45), or\n",
    "   - With phase contrast (Lines 14-55 of Step 45)\n",
    "4. Apply the LSF (Lines 57-60 of Step 45)\n",
    "5. Apply the flat-field correction (Step 62)\n",
    "6. Add Poison noise (Step~\\ref{??})\n",
    "7. Apply the minus log normalisation to compute the sinogram (Step 63)\n",
    "\n",
    "Compute the raw projections and save the data. For this  purpose, we define a new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomographyAcquisition():\n",
    "    \"\"\"\n",
    "    This function simulate a CT acquisition.\n",
    "\n",
    "    :return the raw projections in keV\n",
    "    \"\"\"\n",
    "\n",
    "    # Crete a new array to save every projection in default unit of energy\n",
    "    raw_projections = [];\n",
    "\n",
    "    # For each angle, simulate a projection\n",
    "    for angle_id in range(0, number_of_projections):\n",
    "\n",
    "        # Reset the transformation matrix and rotate the scnned object\n",
    "        gvxr.resetSceneTransformation();\n",
    "        gvxr.rotateScene(-angular_step * angle_id, 0, 1, 0);\n",
    "\n",
    "        # Compute the X-ray image\n",
    "        xray_image = np.array(gvxr.computeXRayImage());\n",
    "\n",
    "        # Add the projection\n",
    "        raw_projections.append(xray_image);\n",
    "\n",
    "    # Convert from the default unit of energy to keV\n",
    "    raw_projections = np.array(raw_projections);\n",
    "    raw_projections_in_keV = raw_projections / gvxr.getUnitOfEnergy(\"keV\");\n",
    "\n",
    "    return raw_projections_in_keV;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat-filed correction\n",
    "\n",
    "Because the data suffers from a fixed-pattern noise in X-ray imaging in\n",
    "actual experiments, it is necessary to perform the flat-field correction of\n",
    "the raw projections using:\n",
    "\n",
    "$$\\mathbf{Proj} = \\frac{\\mathbf{I} - \\mathbf{D}}{\\mathbf{F} - \\mathbf{D}}$$\n",
    "$\\mathbf{F}$ (full fields) and $\\mathbf{D}$ (dark fields) are projection images without sample and acquired with and without the X-ray beam turned on respectively.\n",
    "\n",
    "Note that in our example, `raw_projections_in_keV` ($\\mathbf{I}$), `flat_field_image` ($\\mathbf{F}$) and `dark_field_image` ($\\mathbf{D}$) are in keV whereas `corrected_projections` ($\\mathbf{Proj}$) does not have any unit:\n",
    "\n",
    "$$0 \\leq \\mathbf{I} \\leq  \\sum_E N_0(E) \\times E\\\\0 \\leq \\mathbf{Proj} \\leq 1$$\n",
    "\n",
    "We define a new function to compute the flat-field correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatFieldCorrection(raw_projections_in_keV):\n",
    "    \"\"\"\n",
    "    This function applies the flat-field correction on raw projections.\n",
    "\n",
    "    :param 2D_image raw_projections_in_keV: the raw X-ray projections in keV\n",
    "    :return the projections (raw_projections_in_keV) after flat-field correction\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a mock dark field image\n",
    "    dark_field_image = np.zeros(raw_projections_in_keV.shape);\n",
    "\n",
    "    # Create a mock flat field image\n",
    "    flat_field_image = np.ones(raw_projections_in_keV.shape);\n",
    "\n",
    "    # Retrieve the total energy\n",
    "    total_energy = 0.0;\n",
    "    energy_bins = gvxr.getEnergyBins(\"keV\");\n",
    "    photon_count_per_bin = gvxr.getPhotonCountEnergyBins();\n",
    "\n",
    "    for energy, count in zip(energy_bins, photon_count_per_bin):\n",
    "        total_energy += energy * count;\n",
    "    flat_field_image *= total_energy;\n",
    "\n",
    "    # Apply the actual flat-field correction on the raw projections\n",
    "    corrected_projections = (raw_projections_in_keV - dark_field_image) / (flat_field_image - dark_field_image);\n",
    "\n",
    "    return corrected_projections;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to simulate a sinogram acquisition. Phase contrast in the projections can be taken into account or not. Also, Poisson noise can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateSinogram(sigma_set=None, k_set=None, name_set=None):\n",
    "\n",
    "    global lsf_kernel;\n",
    "\n",
    "    # Do not simulate the phase contrast using a Laplacian\n",
    "    if isinstance(sigma_set, NoneType) or isinstance(k_set, NoneType) or isinstance(name_set, NoneType):\n",
    "\n",
    "        # Get the raw projections in keV\n",
    "        raw_projections_in_keV = tomographyAcquisition();\n",
    "\n",
    "    # Simulate the phase contrast using a Laplacian\n",
    "    else:\n",
    "\n",
    "        # Create the convolution filter\n",
    "        pixel_range = np.linspace(-value_range, value_range, num=int(num_samples), endpoint=True)\n",
    "        laplacian_kernels = {};\n",
    "\n",
    "        # Store the L-buffers\n",
    "        L_buffer_set = {};\n",
    "\n",
    "        # Look at all the children of the root node\n",
    "        for label in [\"core\", \"fibre\", \"matrix\"]:\n",
    "            # Get its L-buffer\n",
    "            L_buffer_set[label] = getLBuffer(label);\n",
    "\n",
    "        # Create blank images\n",
    "        raw_projections_in_keV = np.zeros(L_buffer_set[\"fibre\"].shape);\n",
    "        phase_contrast_image = np.zeros(L_buffer_set[\"fibre\"].shape);\n",
    "\n",
    "        for label, k, sigma in zip(name_set, k_set, sigma_set):\n",
    "            laplacian_kernels[label] = k * laplacian(pixel_range, sigma);\n",
    "\n",
    "            for z in range(phase_contrast_image.shape[0]):\n",
    "                for y in range(phase_contrast_image.shape[1]):\n",
    "                    phase_contrast_image[z][y] += ndimage.convolve((L_buffer_set[label])[z][y], laplacian_kernels[label], mode='wrap');\n",
    "\n",
    "        for energy, photon_count in zip(gvxr.getEnergyBins(\"keV\"), gvxr.getPhotonCountEnergyBins()):\n",
    "\n",
    "            # Create a blank image\n",
    "            attenuation = np.zeros(L_buffer_set[\"fibre\"].shape);\n",
    "\n",
    "            # Look at all the children of the root node\n",
    "            # for label in [\"core\", \"fibre\", \"matrix\"]:\n",
    "            for label in [\"core\", \"fibre\", \"matrix\"]:\n",
    "                # Get mu for this object for this energy\n",
    "                mu = gvxr.getLinearAttenuationCoefficient(label, energy, \"keV\");\n",
    "\n",
    "                # Compute sum mu * x\n",
    "                attenuation += L_buffer_set[label] * mu;\n",
    "\n",
    "            # Store the projection for this energy channel\n",
    "            raw_projections_in_keV += energy * photon_count * np.exp(-attenuation);\n",
    "\n",
    "        # Apply the phase contrast\n",
    "        raw_projections_in_keV -= phase_contrast_image;\n",
    "\n",
    "    # Apply the LSF line by line\n",
    "    for z in range(raw_projections_in_keV.shape[0]):\n",
    "        for y in range(raw_projections_in_keV.shape[1]):\n",
    "            raw_projections_in_keV[z][y] = ndimage.convolve(raw_projections_in_keV[z][y], lsf_kernel, mode='wrap');\n",
    "\n",
    "    # Flat-field correction\n",
    "    normalised_projections = flatFieldCorrection(raw_projections_in_keV);\n",
    "    normalised_projections[normalised_projections < 0] = 0;\n",
    "\n",
    "    # Add noise\n",
    "    if not isinstance(bias, NoneType) and not isinstance(gain, NoneType) and not isinstance(scale, NoneType):\n",
    "\n",
    "        map = (normalised_projections + (bias + 1)) * gain;\n",
    "        temp = np.random.poisson(map).astype(float);\n",
    "        temp /= gain;\n",
    "        temp -= bias + 1;\n",
    "\n",
    "        # Noise map\n",
    "        noise_map = (normalised_projections - temp) * scale;\n",
    "        normalised_projections += noise_map;\n",
    "\n",
    "    # Linearise\n",
    "    simulated_sinogram = computeSinogramFromFlatField(normalised_projections);\n",
    "\n",
    "    return simulated_sinogram, normalised_projections, raw_projections_in_keV;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used quantify the differences between two images. It is used in the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ref, test):\n",
    "\n",
    "    normalised_ref = ref.flatten();\n",
    "    normalised_test = test.flatten();\n",
    "\n",
    "    if use_normalisation or metrics_type == \"ZNCC\":\n",
    "        normalised_ref = standardisation(normalised_ref);\n",
    "        normalised_test = standardisation(normalised_test);\n",
    "\n",
    "    # Mean absolute error\n",
    "    if metrics_type == \"MAE\":\n",
    "        return mean_absolute_error(normalised_ref, normalised_test);\n",
    "    # RMSE\n",
    "    elif metrics_type == \"RMSE\":\n",
    "        return math.sqrt(mean_squared_error(normalised_ref, normalised_test));\n",
    "    # Mean relative error\n",
    "    elif metrics_type == \"MRE\" or metrics_type == \"MAPE\":\n",
    "\n",
    "        # Prevent division by zero\n",
    "        denominator = np.abs(np.subtract(normalised_ref, normalised_test)) + 1e-6;\n",
    "        divisor = np.abs(normalised_ref) + 1e-6;\n",
    "\n",
    "        return np.mean(np.divide(denominator, divisor));\n",
    "    elif metrics_type == \"SSIM\" or metrics_type == \"DSSIM\":\n",
    "        normalised_ref.shape = [900, 1024];\n",
    "        normalised_test.shape = [900, 1024];\n",
    "        return (1.0 - ssim(normalised_ref, normalised_test,\n",
    "                  data_range=normalised_ref.max() - normalised_ref.min())) / 2.0;\n",
    "    elif metrics_type == \"ZNCC\":\n",
    "        return (1.0 - np.mean(np.multiply(normalised_ref, normalised_test))) / 2.0;\n",
    "    else:\n",
    "        raise \"Unknown metrics\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is the objective function used to register the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessFunctionCube(x):\n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global prefix;\n",
    "\n",
    "    global reference_sinogram;\n",
    "    global centroid_set;\n",
    "    global use_fibres;\n",
    "\n",
    "    global core_radius;\n",
    "    global fibre_radius;\n",
    "\n",
    "    # Load the matrix geometrical properties from x\n",
    "    setMatrix(x);\n",
    "\n",
    "    # Simulate a sinogram\n",
    "    simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "    # Compute the objective value\n",
    "    if use_sinogram:\n",
    "        objective = metrics(reference_sinogram, simulated_sinogram);\n",
    "    else:\n",
    "        objective = metrics(reference_normalised_projections, normalised_projections);\n",
    "\n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "\n",
    "        gvxr.saveSTLfile(\"matrix\", \"outputs/matrix_\" + str(best_fitness_id) + \".stl\");\n",
    "\n",
    "        # Reconstruct the CT slice\n",
    "        simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                                    theta_rad,\n",
    "                                    center=rot_center,\n",
    "                                    sinogram_order=False,\n",
    "                                    algorithm='gridrec',\n",
    "                                    filter_name='shepp',\n",
    "                                    ncore=40)[0];\n",
    "\n",
    "        # Save the simulated sinogram\n",
    "        simulated_sinogram.shape = (simulated_sinogram.size // simulated_sinogram.shape[2], simulated_sinogram.shape[2]);\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_sinogram_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_sinogram,\n",
    "                [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_CT_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_CT,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + str(best_fitness_id) + \".dat\", x, header='x,y,rotation_angle,w,h');\n",
    "\n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/cube.dat\"):\n",
    "    matrix_geometry_parameters = np.loadtxt(\"outputs/cube.dat\");\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"cube_\";\n",
    "\n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-2);\n",
    "    opts['tolx'] = 1e-2;\n",
    "    opts['bounds'] = [5*[-0.5], 5*[0.5]];\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy([0.0, 0.0, 0.0, 0.256835938, 0.232903226], 0.5, opts);\n",
    "    es.optimize(fitnessFunctionCube);\n",
    "\n",
    "    matrix_geometry_parameters = copy.deepcopy(es.result.xbest);\n",
    "    np.savetxt(\"outputs/cube.dat\", matrix_geometry_parameters, header='x,y,rotation_angle,w,h');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the result of the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "setMatrix(matrix_geometry_parameters);\n",
    "gvxr.saveSTLfile(\"matrix\", \"outputs/matrix.stl\");\n",
    "\n",
    "# Translation vector\n",
    "x = matrix_geometry_parameters[0] * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "y = matrix_geometry_parameters[1] * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "\n",
    "# Rotation angle\n",
    "rotation_angle_in_degrees = (matrix_geometry_parameters[2] + 0.5) * 180.0;\n",
    "\n",
    "# Scaling factors\n",
    "w = (matrix_geometry_parameters[3] + 0.5) * detector_width_in_pixels * pixel_spacing_in_micrometre;\n",
    "h = (matrix_geometry_parameters[4] + 0.5) * w;\n",
    "\n",
    "print(\"Matrix\");\n",
    "print(\"\\tposition:\", x, y, \"um\");\n",
    "print(\"\\trotation:\", rotation_angle_in_degrees, \"deg\");\n",
    "print(\"\\tsize:\", w, h, \"um\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the correspond CT acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a sinogram\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram();\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC matrix registration:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the result of the registration as an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAnimation(aPrefix, anOutputFile):\n",
    "    # Find all the images from the output directory\n",
    "    files = sorted(\n",
    "        glob.glob(aPrefix + \"[0-9]*.mha\"))\n",
    "\n",
    "    # Store the images\n",
    "    registration_image_set = [];\n",
    "\n",
    "    # Create the GIF file\n",
    "    with imageio.get_writer(anOutputFile, mode='I') as writer:\n",
    "\n",
    "        # Store the PNG filenames\n",
    "        png_filename_set = [];\n",
    "\n",
    "        # Process all the images\n",
    "        for i in range(len(files)):\n",
    "            # Create the filenames\n",
    "            mha_fname = aPrefix + str(i) + \".mha\";\n",
    "            png_filename_set.append(aPrefix + str(i) + \".png\");\n",
    "\n",
    "            # Open the MHA file\n",
    "            float_image = sitk.ReadImage(mha_fname);\n",
    "\n",
    "            # Convert in a Numpy array\n",
    "            narray = sitk.GetArrayFromImage(float_image);\n",
    "\n",
    "            offset = 60;\n",
    "            roi_ref = reference_CT[505 - offset:505 + offset + 1,501 - offset:501 + offset + 1];\n",
    "            roi_sim = narray[505 - offset:505 + offset + 1,501 - offset:501 + offset + 1];\n",
    "\n",
    "            narray = standardisation(narray);\n",
    "            registration_image_set.append(narray);\n",
    "\n",
    "            # Create the figure\n",
    "            fig, axs = plt.subplots(3, 3)\n",
    "\n",
    "            # Dispay the reference, registration and error map\n",
    "            fig.suptitle('Registration: Result ' + str(i+1) + \"/\" + str(len(files)))\n",
    "            plt.tight_layout();\n",
    "            norm = cm.colors.Normalize(vmax=1.25, vmin=-0.5)\n",
    "\n",
    "            comp_equalized = compare_images(normalised_reference_CT, narray, method='checkerboard');\n",
    "\n",
    "            roi_normalised_ref = normalised_reference_CT[505 - offset:505 + offset + 1,501 - offset:501 + offset + 1];\n",
    "            roi_normalised_sim = narray[505 - offset:505 + offset + 1,501 - offset:501 + offset + 1];\n",
    "            roi_normalised_compare = comp_equalized[505 - offset:505 + offset + 1,501 - offset:501 + offset + 1];\n",
    "\n",
    "\n",
    "            # Reference\n",
    "            axs[0, 0].set_title(\"Reference image\");\n",
    "            axs[0, 0].imshow(normalised_reference_CT, cmap=\"gray\", norm=norm);\n",
    "            axs[1, 0].imshow(roi_normalised_ref, cmap=\"gray\", norm=norm);\n",
    "            axs[2, 0].axis('off');\n",
    "\n",
    "            # Registration\n",
    "            axs[0, 1].set_title(\"Simulated CT slice after automatic registration\");\n",
    "            axs[0, 1].imshow(narray, cmap='gray', norm=norm);\n",
    "            axs[1, 1].imshow(roi_normalised_sim, cmap=\"gray\", norm=norm);\n",
    "\n",
    "            axs[2, 1].set_title(\"Diagonal profiles\");\n",
    "            axs[2, 1].plot(np.diag(roi_ref), label=\"Reference\");\n",
    "            axs[2, 1].plot(np.diag(roi_sim), label=\"Simulated\");\n",
    "            # axs[2, 1].plot(np.diag(roi_ref) - np.diag(roi_sim), label=\"Error\");\n",
    "            axs[2, 1].legend();\n",
    "\n",
    "            # Error map\n",
    "            ZNCC = 100.0 * np.mean(np.multiply(normalised_reference_CT, narray));\n",
    "            axs[0, 2].set_title(\"Checkboard comparison between\\nthe reference and simulated images\\nZNCC: \" + \"{:.2f}\".format(ZNCC));\n",
    "            axs[0, 2].imshow(comp_equalized, cmap='gray', norm=norm);\n",
    "            axs[1, 2].imshow(roi_normalised_compare, cmap='gray', norm=norm);\n",
    "            axs[2, 2].axis('off');\n",
    "\n",
    "            plt.tight_layout();\n",
    "\n",
    "            # Save the figure as a PNG file\n",
    "            plt.savefig(png_filename_set[i])\n",
    "\n",
    "            # Close the figure\n",
    "            plt.close()\n",
    "\n",
    "            # Open the PNG file with imageio and add it to the GIF file\n",
    "            image = imageio.imread(png_filename_set[i])\n",
    "            writer.append_data(image)\n",
    "\n",
    "            # Delete the PNG file\n",
    "            os.remove(png_filename_set[i]);\n",
    "\n",
    "        for i in range(15):\n",
    "            writer.append_data(image)\n",
    "\n",
    "    return registration_image_set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/cube_registration.gif\"):\n",
    "    cube_registration_image_set = createAnimation(\"outputs/cube_simulated_CT_\",\n",
    "                'plots/cube_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Animation of the registration (GIF file)](plots/cube_registration.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the fibres\n",
    "\n",
    "The radius of a tungsten core is 30 / 2 um. The pixel spacing is 1.9 um. The radius in number of pixels is $15/1.9  \\approx  7.89$. The area of a core is $(15/1.9)^2  \\pi  \\approx 196$ pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setMatrix(matrix_geometry_parameters);\n",
    "setFibres(centroid_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a sinogram\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC matrix registration with fibres:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sinogram.shape     = (simulated_sinogram.size     // simulated_sinogram.shape[2],     simulated_sinogram.shape[2]);\n",
    "normalised_projections.shape = (normalised_projections.size // normalised_projections.shape[2], normalised_projections.shape[2]);\n",
    "raw_projections_in_keV.shape = (raw_projections_in_keV.size // raw_projections_in_keV.shape[2], raw_projections_in_keV.shape[2]);\n",
    "\n",
    "saveMHA(\"outputs/simulated_sinogram_with_fibres.mha\",\n",
    "        simulated_sinogram,\n",
    "        [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "saveMHA(\"outputs/normalised_projections_with_fibres.mha\",\n",
    "        normalised_projections,\n",
    "        [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "saveMHA(\"outputs/raw_projections_in_keV_with_fibres.mha\",\n",
    "        raw_projections_in_keV,\n",
    "        [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA(\"outputs/simulated_CT_with_fibres.mha\",\n",
    "        simulated_CT,\n",
    "        [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "saveMHA(\"outputs/normalised_simulated_CT_with_fibres.mha\",\n",
    "        normalised_simulated_CT,\n",
    "        [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = cm.colors.Normalize(vmax=1.25, vmin=-0.5)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('CT slice with fibres after the registration')\n",
    "\n",
    "ax1.set_title(\"Reference image\");\n",
    "imgplot1 = ax1.imshow(normalised_reference_CT, cmap=\"gray\", \n",
    "                     norm=norm);\n",
    "\n",
    "ax2.set_title(\"Simulated CT slice after automatic registration\");\n",
    "imgplot2 = ax2.imshow(normalised_simulated_CT,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "comp_equalized = compare_images(normalised_reference_CT, normalised_simulated_CT, method='checkerboard');\n",
    "ax3.set_title(\"Checkboard comparison between\\n\" + \n",
    "              \"the reference and simulated images\\nZNCC: \" + \n",
    "              \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));\n",
    "imgplot3 = ax3.imshow(comp_equalized,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "plt.savefig('plots/simulated_CT_slice_with_fibres_after_cube_registration.pdf');\n",
    "plt.savefig('plots/simulated_CT_slice_with_fibres_after_cube_registration.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Registration of a cube](plots/simulated_CT_slice_with_fibres_after_cube_registration.png)\n",
    "\n",
    "## Optimisation of the cores and fibres radii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is the objective function used to optimise the radii of the cores and fibres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessFunctionFibres(x):\n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global fibre_radius;\n",
    "    global core_radius;\n",
    "    global prefix;\n",
    "\n",
    "    # Get the radii\n",
    "    fibre_radius = x[0];\n",
    "    core_radius = fibre_radius * x[1];\n",
    "\n",
    "    # Load the matrix\n",
    "    setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "    # Load the cores and fibres\n",
    "    setFibres(centroid_set);\n",
    "\n",
    "    # Simulate a sinogram\n",
    "    simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "    # Compute the objective value\n",
    "    if use_sinogram:\n",
    "        objective = metrics(reference_sinogram, simulated_sinogram);\n",
    "    else:\n",
    "        objective = metrics(reference_normalised_projections, normalised_projections);\n",
    "\n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "        \n",
    "        gvxr.saveSTLfile(\"core\",  \"outputs/\" + prefix + str(best_fitness_id) + \"_cores.stl\");\n",
    "        gvxr.saveSTLfile(\"fibre\", \"outputs/\" + prefix + str(best_fitness_id) + \"_fibres.stl\");\n",
    "        \n",
    "        # Reconstruct the CT slice\n",
    "        simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                                    theta_rad,\n",
    "                                    center=rot_center,\n",
    "                                    sinogram_order=False,\n",
    "                                    algorithm='gridrec',\n",
    "                                    filter_name='shepp',\n",
    "                                    ncore=40)[0];\n",
    "        \n",
    "        # Save the simulated sinogram\n",
    "        simulated_sinogram.shape = (simulated_sinogram.size // simulated_sinogram.shape[2], simulated_sinogram.shape[2]);\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_sinogram_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_sinogram,\n",
    "                [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_CT_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_CT,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + str(best_fitness_id) + \".dat\", x, header='x,y,rotation_angle,w,h');\n",
    "\n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/fibre1_radii.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/fibre1_radii.dat\");\n",
    "    core_radius = temp[0];\n",
    "    fibre_radius = temp[1];\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "    ratio = core_radius / fibre_radius;\n",
    "\n",
    "    x0 = [fibre_radius, ratio];\n",
    "    bounds = [[5, 0.01], [1.5 * fibre_radius, 0.95]];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"fibre1_\";\n",
    "    \n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-3);\n",
    "    opts['tolx'] = 1e-3;\n",
    "    opts['bounds'] = bounds;\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.9, opts);\n",
    "    es.optimize(fitnessFunctionFibres);\n",
    "    fibre_radius = es.result.xbest[0];\n",
    "    core_radius = fibre_radius * es.result.xbest[1];\n",
    "\n",
    "    np.savetxt(\"outputs/fibre1_radii.dat\", [core_radius, fibre_radius], header='core_radius_in_um,fibre_radius_in_um');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/fibre1_registration.gif\"):\n",
    "    registration_image_set = createAnimation(\"outputs/fibre1_simulated_CT_\",\n",
    "                'plots/fibre1_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Animation of the registration (GIF file)](plots/fibre1_registration.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply the result of the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the matrix\n",
    "setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "# Load the cores and fibres\n",
    "setFibres(centroid_set);\n",
    "\n",
    "gvxr.saveSTLfile(\"fibre\", \"outputs/fibre1_fibre.stl\");\n",
    "gvxr.saveSTLfile(\"core\",  \"outputs/fibre1_core.stl\");\n",
    "\n",
    "print(\"Core diameter:\", round(core_radius * 2), \"um\");\n",
    "print(\"Fibre diameter:\", round(fibre_radius * 2), \"um\");\n",
    "\n",
    "# Simulate the corresponding CT aquisition\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC radii registration 1:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3D view of the registration looks like:\n",
    "\n",
    "![3D view](./3d-view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recentre each core/fibre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each fibre is extracted from both the reference CT slice and simulated CT slice. The displacement between the corresponding fibres is computed to maximise the ZNCC between the two. The centre of the fibre is then adjusted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineCentrePositions(centroid_set, reconstruction_CT_fibres):\n",
    "\n",
    "    # Exhaustive local search to refine the centre of each cylinder\n",
    "    roi_length = 40;\n",
    "    new_centroid_set = [];\n",
    "    for i, cyl in enumerate(centroid_set):\n",
    "\n",
    "        centre = [\n",
    "            cyl[0],\n",
    "            cyl[1]\n",
    "        ];\n",
    "\n",
    "        # extract ROI from reference image\n",
    "        reference_image = copy.deepcopy(reference_CT[centre[1] - roi_length:centre[1] + roi_length, centre[0] - roi_length:centre[0] + roi_length]);\n",
    "\n",
    "        # Normalise ROI\n",
    "        reference_image = standardisation(reference_image);\n",
    "\n",
    "        best_ZNCC = -1;\n",
    "        best_x_offset = 0;\n",
    "        best_y_offset = 0;\n",
    "\n",
    "        for y in range(-10, 11):\n",
    "            for x in range(-10, 11):\n",
    "\n",
    "                centre = [\n",
    "                    cyl[0] + x,\n",
    "                    cyl[1] + y\n",
    "                ];\n",
    "\n",
    "                # extract ROI from test image\n",
    "                test_image = copy.deepcopy(reconstruction_CT_fibres[centre[1] - roi_length:centre[1] + roi_length, centre[0] - roi_length:centre[0] + roi_length]);\n",
    "\n",
    "                # Normalise ROI\n",
    "                test_image = standardisation(test_image);\n",
    "\n",
    "                # Compare the ROIs\n",
    "                zncc = np.mean(np.multiply(reference_image.flatten(), test_image.flatten()));\n",
    "\n",
    "                if best_ZNCC < zncc:\n",
    "                    best_ZNCC = zncc;\n",
    "                    best_x_offset = x;\n",
    "                    best_y_offset = y;\n",
    "\n",
    "        # Correct the position of the centre of the fibre\n",
    "        new_centroid_set.append([cyl[0] - best_x_offset, cyl[1] - best_y_offset]);\n",
    "\n",
    "    return new_centroid_set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_set = refineCentrePositions(centroid_set, normalised_simulated_CT);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the result of recentring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix\n",
    "setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "# Load the cores and fibres\n",
    "setFibres(centroid_set);\n",
    "\n",
    "gvxr.saveSTLfile(\"fibre\", \"outputs/fibre2_fibre.stl\");\n",
    "gvxr.saveSTLfile(\"core\",  \"outputs/fibre2_core.stl\");\n",
    "\n",
    "# Simulate the corresponding CT aquisition\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC recentring registration:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation the radii after recentring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After recentring the centres, another run of optimisation is executed to refine the radii of the fibres and cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/fibre3_radii.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/fibre3_radii.dat\");\n",
    "    core_radius = temp[0];\n",
    "    fibre_radius = temp[1];\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "    ratio = core_radius / fibre_radius;\n",
    "\n",
    "    x0 = [fibre_radius, ratio];\n",
    "    bounds = [[5, 0.01], [1.5 * fibre_radius, 0.95]];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"fibre3_\";\n",
    "\n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-2);\n",
    "    opts['tolx'] = 1e-2;\n",
    "    opts['bounds'] = bounds;\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.9, opts);\n",
    "    es.optimize(fitnessFunctionFibres);\n",
    "    fibre_radius = es.result.xbest[0];\n",
    "    core_radius = fibre_radius * es.result.xbest[1];\n",
    "\n",
    "    np.savetxt(\"outputs/fibre3_radii.dat\", [core_radius, fibre_radius], header='core_radius_in_um,fibre_radius_in_um');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/fibre3_registration.gif\"):\n",
    "    registration_image_set = createAnimation(\"outputs/fibre3_simulated_CT_\",\n",
    "                'plots/fibre3_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Animation of the registration (GIF file)](plots/fibre3_registration.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply the result of the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the matrix\n",
    "setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "# Load the cores and fibres\n",
    "setFibres(centroid_set);\n",
    "\n",
    "gvxr.saveSTLfile(\"fibre\", \"outputs/fibre3_fibre.stl\");\n",
    "gvxr.saveSTLfile(\"core\",  \"outputs/fibre3_core.stl\");\n",
    "\n",
    "print(\"Core diameter:\", round(core_radius * 2), \"um\");\n",
    "print(\"Fibre diameter:\", round(fibre_radius * 2), \"um\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate the corresponding CT aquisition\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC radii registration 2:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation of the beam spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessHarmonics(x):\n",
    "\n",
    "    global energy_spectrum;\n",
    "    \n",
    "    global use_normalisation;\n",
    "    \n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global prefix;\n",
    "    \n",
    "    energy_33_keV = x[0];\n",
    "    first_order_harmonics = x[1];\n",
    "    second_order_harmonics = x[2];\n",
    "\n",
    "    # Normalise the beam spectrum\n",
    "    total = energy_33_keV + first_order_harmonics + second_order_harmonics;\n",
    "    energy_33_keV /= total;\n",
    "    first_order_harmonics /= total;\n",
    "    second_order_harmonics /= total;\n",
    "\n",
    "    # The beam specturm. Here we have a polychromatic beam.\n",
    "    gvxr.resetBeamSpectrum();\n",
    "    energy_spectrum = [(33, energy_33_keV, \"keV\"), (66, first_order_harmonics, \"keV\"), (99, second_order_harmonics, \"keV\")];\n",
    "\n",
    "    for energy, percentage, unit in energy_spectrum:\n",
    "        gvxr.addEnergyBinToSpectrum(energy, unit, percentage);\n",
    "\n",
    "    # Simulate a sinogram\n",
    "    simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "    # Compute the objective value (no normalisation here)\n",
    "    old_normalisation = use_normalisation;\n",
    "    use_normalisation = False;\n",
    "    if use_sinogram:\n",
    "        objective = metrics(reference_sinogram, simulated_sinogram);\n",
    "    else:\n",
    "        objective = metrics(reference_normalised_projections, normalised_projections);\n",
    "    use_normalisation = old_normalisation;\n",
    "   \n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "        \n",
    "        # Reconstruct the CT slice\n",
    "        simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                                    theta_rad,\n",
    "                                    center=rot_center,\n",
    "                                    sinogram_order=False,\n",
    "                                    algorithm='gridrec',\n",
    "                                    filter_name='shepp',\n",
    "                                    ncore=40)[0];\n",
    "\n",
    "        # Save the simulated sinogram\n",
    "        simulated_sinogram.shape = (simulated_sinogram.size // simulated_sinogram.shape[2], simulated_sinogram.shape[2]);\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_sinogram_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_sinogram,\n",
    "                [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "        \n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_CT_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_CT,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + str(best_fitness_id) + \".dat\", np.array(x) / total, header='33keV,66keV,99keV');\n",
    "\n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/spectrum1.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/spectrum1.dat\");\n",
    "\n",
    "    # The beam specturm. Here we have a polychromatic beam.\n",
    "    energy_spectrum = [(33, temp[0], \"keV\"), (66, temp[1], \"keV\"), (99, temp[2], \"keV\")];\n",
    "\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "    ratio = core_radius / fibre_radius;\n",
    "\n",
    "    x0 = [0.97, 0.2, 0.1];\n",
    "    bounds = [[0.0, 0.0, 0.0], [1.0, 1.0, 1.0]];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"spectrum1_\";\n",
    "    \n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-2);\n",
    "    opts['tolx'] = 1e-2;\n",
    "    opts['bounds'] = bounds;\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.25, opts);\n",
    "    es.optimize(fitnessHarmonics);\n",
    "\n",
    "    total = es.result.xbest[0] + es.result.xbest[1] + es.result.xbest[2];\n",
    "    energy_spectrum = [(33, es.result.xbest[0] / total, \"keV\"), (66, es.result.xbest[1] / total, \"keV\"), (99, es.result.xbest[2] / total, \"keV\")];\n",
    "\n",
    "    np.savetxt(\"outputs/spectrum1.dat\", [es.result.xbest[0] / total, es.result.xbest[1] / total, es.result.xbest[2] / total], header='weight of main energy,weight of first order harmonics,weight of second order harmonics');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/spectrum1_registration.gif\"):\n",
    "    registration_image_set = createAnimation(\"outputs/spectrum1_simulated_CT_\",\n",
    "                'plots/spectrum1_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Animation of the registration (GIF file)](plots/spectrum1_registration.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the result of the registration\n",
    "gvxr.resetBeamSpectrum();\n",
    "for energy, percentage, unit in energy_spectrum:\n",
    "    gvxr.addEnergyBinToSpectrum(energy, unit, percentage);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for channel in energy_spectrum:\n",
    "    print(channel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate the corresponding CT aquisition\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC spectrum registration 1:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation of the phase contrast and the radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(x, sigma):\n",
    "    \"\"\"\n",
    "    This function create a Laplacian kernel with\n",
    "\n",
    "    $$ g''(x) = \\left(\\frac{x^2}{\\sigma^4} - \\frac{1}{\\sigma^2}\\right) \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) $$\n",
    "    \n",
    "    :param array x: \n",
    "    :param float sigma:\n",
    "    :return the convolution kernel\n",
    "    \"\"\"\n",
    "    \n",
    "    return (np.power(x, 2.) / math.pow(sigma, 4) - 1. / math.pow(sigma, 2)) * np.exp(-np.power(x, 2.) / (2. * math.pow(sigma, 2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLBuffer(object):\n",
    "\n",
    "    \"\"\"\n",
    "    This function compute the L-buffer of the object over all the angles\n",
    "    \n",
    "    :param str object: the name of the object \n",
    "    :return the L-buffer over all the angles\n",
    "    \"\"\"\n",
    "\n",
    "    # An empty L-buffer\n",
    "    L_buffer = [];\n",
    "\n",
    "    # Get the line of L-buffer for each angle\n",
    "    for angle_id in range(0, number_of_projections):\n",
    "        gvxr.resetSceneTransformation();\n",
    "        gvxr.rotateScene(-angular_step * angle_id, 0, 1, 0);\n",
    "\n",
    "        # Compute the X-ray image\n",
    "        line_of_L_buffer = np.array(gvxr.computeLBuffer(object));\n",
    "\n",
    "        # Add the projection\n",
    "        L_buffer.append(line_of_L_buffer);\n",
    "\n",
    "    # Return as a numpy array\n",
    "    return np.array(L_buffer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessFunctionLaplacian(x):\n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global prefix;\n",
    "    \n",
    "    global fibre_radius;\n",
    "    global core_radius;\n",
    "\n",
    "    sigma_core = x[0];\n",
    "    k_core = x[1];\n",
    "    sigma_fibre = x[2];\n",
    "    k_fibre = x[3];\n",
    "    sigma_matrix = x[4];\n",
    "    k_matrix = x[5];\n",
    "    core_radius = x[6];\n",
    "    fibre_radius = x[7];\n",
    "\n",
    "    # Load the matrix\n",
    "    setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "    # Load the cores and fibres\n",
    "    setFibres(centroid_set);\n",
    "\n",
    "    # Simulate a sinogram\n",
    "    simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(\n",
    "        [sigma_core, sigma_fibre, sigma_matrix], \n",
    "        [k_core, k_fibre, k_matrix], \n",
    "        [\"core\", \"fibre\", \"matrix\"]\n",
    "    );\n",
    "\n",
    "    # Compute the objective value\n",
    "    if use_sinogram:\n",
    "        objective = metrics(reference_sinogram, simulated_sinogram);\n",
    "    else:\n",
    "        objective = metrics(reference_normalised_projections, normalised_projections);\n",
    "   \n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "                \n",
    "        # Reconstruct the CT slice\n",
    "        simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                                    theta_rad,\n",
    "                                    center=rot_center,\n",
    "                                    sinogram_order=False,\n",
    "                                    algorithm='gridrec',\n",
    "                                    filter_name='shepp',\n",
    "                                    ncore=40)[0];\n",
    "\n",
    "        # Save the simulated sinogram\n",
    "        simulated_sinogram.shape = (simulated_sinogram.size // simulated_sinogram.shape[2], simulated_sinogram.shape[2]);\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_sinogram_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_sinogram,\n",
    "                [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_CT_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_CT,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + str(best_fitness_id) + \".dat\", [sigma_core, k_core, sigma_fibre, k_fibre, sigma_matrix, k_matrix, core_radius, fibre_radius], header='sigma_core, k_core, sigma_fibre, k_fibre, sigma_matrix, k_matrix, core_radius_in_um, fibre_radius_in_um');\n",
    "    \n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/laplacian1.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/laplacian1.dat\");\n",
    "    sigma_core = temp[0];\n",
    "    k_core = temp[1];\n",
    "    sigma_fibre = temp[2];\n",
    "    k_fibre = temp[3];\n",
    "    sigma_matrix = temp[4];\n",
    "    k_matrix = temp[5];\n",
    "    core_radius = temp[6];\n",
    "    fibre_radius = temp[7];\n",
    "\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "\n",
    "    sigma_core = 5.;\n",
    "    sigma_fibre = 0.75;\n",
    "    sigma_matrix = 0.6;\n",
    "\n",
    "    k_core = 1000;\n",
    "    k_fibre = 1000;\n",
    "    k_matrix = 1000.0;\n",
    "\n",
    "    x0 = [\n",
    "        sigma_core, k_core, \n",
    "        sigma_fibre, k_fibre, \n",
    "        sigma_matrix, k_matrix, \n",
    "        core_radius, fibre_radius\n",
    "    ];\n",
    "    \n",
    "    bounds = [\n",
    "        [\n",
    "            0.005, 0.0, \n",
    "             0.005, 0.0, \n",
    "             0.005, 0.0, \n",
    "             0.95 * core_radius, 0.95 * fibre_radius\n",
    "        ],\n",
    "        [\n",
    "            10.0, 2000, \n",
    "             2.5, 2000, \n",
    "             2.5, 2000, \n",
    "             1.15 * core_radius, 1.15 * fibre_radius\n",
    "        ]\n",
    "    ];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"laplacian1_\";\n",
    "\n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-4);\n",
    "    opts['tolx'] = 1e-4;\n",
    "    opts['bounds'] = bounds;\n",
    "    opts['CMA_stds'] = [0.25, 20.25, 0.25, 20.25, 0.25, 20.25, core_radius * 0.1, fibre_radius * 0.1];\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.25, opts);\n",
    "    es.optimize(fitnessFunctionLaplacian);\n",
    "\n",
    "    sigma_core = es.result.xbest[0];\n",
    "    k_core = es.result.xbest[1];\n",
    "    sigma_fibre = es.result.xbest[2];\n",
    "    k_fibre = es.result.xbest[3];\n",
    "    sigma_matrix = es.result.xbest[4];\n",
    "    k_matrix = es.result.xbest[5];\n",
    "    core_radius = es.result.xbest[6];\n",
    "    fibre_radius = es.result.xbest[7];\n",
    "\n",
    "    np.savetxt(\"outputs/laplacian1.dat\", [sigma_core, k_core, sigma_fibre, k_fibre, sigma_matrix, k_matrix, core_radius, fibre_radius], header='sigma_core, k_core, sigma_fibre, k_fibre, sigma_matrix, k_matrix, core_radius_in_um, fibre_radius_in_um');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/laplacian1_registration.gif\"):\n",
    "    registration_image_set = createAnimation(\"outputs/laplacian1_simulated_CT_\",\n",
    "                'plots/laplacian1_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Animation of the registration (GIF file)](./plots/laplacian1_registration.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply the result of the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the matrix\n",
    "setMatrix(matrix_geometry_parameters);\n",
    "\n",
    "# Load the cores and fibres\n",
    "setFibres(centroid_set);\n",
    "\n",
    "gvxr.saveSTLfile(\"fibre\", \"outputs/laplacian1_fibre.stl\");\n",
    "gvxr.saveSTLfile(\"core\",  \"outputs/laplacian1_core.stl\");\n",
    "\n",
    "print(\"Core diameter:\", round(core_radius * 2), \"um\");\n",
    "print(\"Fibre diameter:\", round(fibre_radius * 2), \"um\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate the corresponding CT aquisition\n",
    "sigma_set = [sigma_core, sigma_fibre, sigma_matrix];\n",
    "k_set = [k_core, k_fibre, k_matrix]; \n",
    "label_set = [\"core\", \"fibre\", \"matrix\"];\n",
    "\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC phase contrast registration 1:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation of the phase contrast and the LSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lsf = copy.deepcopy(lsf_kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitnessFunctionLaplacianLSF(x):\n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global prefix;\n",
    "    \n",
    "    global lsf_kernel;\n",
    "\n",
    "    # sigma_core = x[0];\n",
    "    k_core = x[0];\n",
    "    # sigma_fibre = x[2];\n",
    "    k_fibre = x[1];\n",
    "    # sigma_matrix = x[4];\n",
    "    k_matrix = x[2];\n",
    "\n",
    "    b2 = x[3];\n",
    "    c2 = x[4];\n",
    "    e2 = x[5];\n",
    "    f2 = x[6];\n",
    "\n",
    "    # The response of the detector as the line-spread function (LSF)\n",
    "    t = np.arange(-20., 21., 1.);\n",
    "    lsf_kernel=lsf(t*41, b2, c2, e2, f2);\n",
    "    lsf_kernel/=lsf_kernel.sum();\n",
    "\n",
    "    # Simulate a sinogram\n",
    "    simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(\n",
    "        [sigma_core, sigma_fibre, sigma_matrix], \n",
    "        [k_core, k_fibre, k_matrix], \n",
    "        [\"core\", \"fibre\", \"matrix\"]\n",
    "    );\n",
    "\n",
    "    # Compute the objective value\n",
    "    if use_sinogram:\n",
    "        objective = metrics(reference_sinogram, simulated_sinogram);\n",
    "    else:\n",
    "        objective = metrics(reference_normalised_projections, normalised_projections);\n",
    "   \n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "        \n",
    "        # Reconstruct the CT slice\n",
    "        simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                                    theta_rad,\n",
    "                                    center=rot_center,\n",
    "                                    sinogram_order=False,\n",
    "                                    algorithm='gridrec',\n",
    "                                    filter_name='shepp',\n",
    "                                    ncore=40)[0];\n",
    "        \n",
    "        # Save the simulated sinogram\n",
    "        simulated_sinogram.shape = (simulated_sinogram.size // simulated_sinogram.shape[2], simulated_sinogram.shape[2]);\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_sinogram_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_sinogram,\n",
    "                [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "        \n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"simulated_CT_\" + str(best_fitness_id) + \".mha\",\n",
    "                simulated_CT,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + \"laplacian_\" + str(best_fitness_id) + \".dat\", [k_core, k_fibre, k_matrix], header='k_core, k_fibre, k_matrix');\n",
    "        np.savetxt(\"outputs/\" + prefix + \"LSF_\" + str(best_fitness_id) + \".dat\", [b2, c2, e2, f2], header='b2, c2, e2, f2');\n",
    "\n",
    "        \n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/laplacian2.dat\") and os.path.isfile(\"outputs/lsf2.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/laplacian2.dat\");\n",
    "    k_core = temp[0];\n",
    "    k_fibre = temp[1];\n",
    "    k_matrix = temp[2];\n",
    "\n",
    "    temp = np.loadtxt(\"outputs/lsf2.dat\");\n",
    "    b2 = temp[0];\n",
    "    c2 = temp[1];\n",
    "    e2 = temp[2];\n",
    "    f2 = temp[3];\n",
    "\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "\n",
    "    b2 = 54.9359;\n",
    "    c2 = -3.58452;\n",
    "    e2 = 6.32561e+09;\n",
    "    f2 = 1.0;\n",
    "\n",
    "    x0 = [\n",
    "        k_core,\n",
    "        k_fibre,\n",
    "        k_matrix,\n",
    "        b2, c2, e2, f2\n",
    "    ];\n",
    "\n",
    "    bounds = [\n",
    "        [\n",
    "            k_core-500,\n",
    "            k_fibre-500,\n",
    "            k_matrix-500,\n",
    "            b2 - b2 / 4.,\n",
    "            c2 + c2 / 4.,\n",
    "            e2 - e2 / 4.,\n",
    "            f2 - f2/ 4.\n",
    "        ],\n",
    "        [\n",
    "            k_core+500,\n",
    "            k_fibre+500,\n",
    "            k_matrix+500,\n",
    "            b2 + b2 / 4.,\n",
    "            c2 - c2 / 4.,\n",
    "            e2 + e2 / 4.,\n",
    "            f2 + f2/ 4.\n",
    "        ]\n",
    "    ];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"laplacian2_\"\n",
    "\n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-4);\n",
    "    opts['tolx'] = 1e-4;\n",
    "    opts['bounds'] = bounds;\n",
    "    #opts['seed'] = 987654321;\n",
    "    # opts['maxiter'] = 5;\n",
    "    opts['CMA_stds'] = [1250 * 0.2, 1250 * 0.2, 1250 * 0.2,\n",
    "        b2 * 0.2, -c2 * 0.2, e2 * 0.2, f2 * 0.2];\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.25, opts);\n",
    "    es.optimize(fitnessFunctionLaplacianLSF);\n",
    "\n",
    "    k_core = es.result.xbest[0];\n",
    "    k_fibre = es.result.xbest[1];\n",
    "    k_matrix = es.result.xbest[2];\n",
    "\n",
    "    b2 = es.result.xbest[3];\n",
    "    c2 = es.result.xbest[4];\n",
    "    e2 = es.result.xbest[5];\n",
    "    f2 = es.result.xbest[6];\n",
    "\n",
    "    np.savetxt(\"outputs/laplacian2.dat\", [k_core, k_fibre, k_matrix], header='k_core, k_fibre, k_matrix');\n",
    "    np.savetxt(\"outputs/lsf2.dat\", [b2, c2, e2, f2], header='b2, c2, e2, f2');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/laplacian2_registration.gif\"):\n",
    "    registration_image_set = createAnimation(\"outputs/laplacian2_simulated_CT_\",\n",
    "                'plots/laplacian2_registration.gif');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Animation of the registration (GIF file)](plots/laplacian2_registration.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the result of the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response of the detector as the line-spread function (LSF)\n",
    "t = np.arange(-20., 21., 1.);\n",
    "lsf_kernel=lsf(t*41, b2, c2, e2, f2);\n",
    "lsf_kernel/=lsf_kernel.sum();\n",
    "np.savetxt(\"outputs/LSF_optimised.txt\", lsf_kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the corresponding CT aquisition\n",
    "sigma_set = [sigma_core, sigma_fibre, sigma_matrix];\n",
    "k_set = [k_core, k_fibre, k_matrix]; \n",
    "label_set = [\"core\", \"fibre\", \"matrix\"];\n",
    "\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);\n",
    "\n",
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "\n",
    "offset1 = 86;\n",
    "offset2 = reference_CT.shape[0] - offset1;\n",
    "profile_test_whole_image_without_Poisson_noise = copy.deepcopy(np.diag(simulated_CT[offset1:offset2, offset1:offset2]));\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC phase contrast and LSF registration:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure();\n",
    "plt.title(\"Response of the detector (LSF)\");\n",
    "plt.plot(t, old_lsf, label=\"Before optimisation\");\n",
    "plt.plot(t, lsf_kernel, label=\"After optimisation\");\n",
    "plt.legend();\n",
    "plt.savefig('plots/LSF_optimised.pdf');\n",
    "plt.savefig('plots/LSF_optimised.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Response of the detector (LSF)](plots/LSF_optimised.png)\n",
    "\n",
    "### Extract the fibre in the centre of the CT slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findFibreInCentreOfCtSlice():\n",
    "    global centroid_set;\n",
    "    global reference_CT;\n",
    "    global cylinder_position_in_centre_of_slice;\n",
    "\n",
    "    # Find the cylinder in the centre of the image\n",
    "    cylinder_position_in_centre_of_slice = None;\n",
    "    best_distance = sys.float_info.max;\n",
    "\n",
    "    for centre in centroid_set:\n",
    "        distance = math.pow(centre[0] - reference_CT.shape[1] / 2,2 ) + math.pow(centre[1] - reference_CT.shape[0] / 2, 2);\n",
    "\n",
    "        if best_distance > distance:\n",
    "            best_distance = distance;\n",
    "            cylinder_position_in_centre_of_slice = copy.deepcopy(centre);\n",
    "\n",
    "    return cylinder_position_in_centre_of_slice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "findFibreInCentreOfCtSlice();\n",
    "\n",
    "reference_fibre_in_centre = np.array(copy.deepcopy(reference_CT[cylinder_position_in_centre_of_slice[1] - roi_length:cylinder_position_in_centre_of_slice[1] + roi_length, cylinder_position_in_centre_of_slice[0] - roi_length:cylinder_position_in_centre_of_slice[0] + roi_length]));\n",
    "test_fibre_in_centre      = np.array(copy.deepcopy(simulated_CT[cylinder_position_in_centre_of_slice[1] - roi_length:cylinder_position_in_centre_of_slice[1] + roi_length, cylinder_position_in_centre_of_slice[0] - roi_length:cylinder_position_in_centre_of_slice[0] + roi_length]));\n",
    "\n",
    "profile_reference = copy.deepcopy(np.diag(reference_fibre_in_centre));\n",
    "profile_test_without_Poisson_noise = copy.deepcopy(np.diag(test_fibre_in_centre));\n",
    "\n",
    "reference_fibre_in_centre = standardisation(reference_fibre_in_centre);\n",
    "test_fibre_in_centre = standardisation(test_fibre_in_centre);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm = cm.colors.Normalize(vmax=1.25, vmin=-0.5)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Fibre in the centre of the CT slices')\n",
    "\n",
    "ax1.set_title(\"Reference image\");\n",
    "imgplot1 = ax1.imshow(reference_fibre_in_centre, cmap=\"gray\", \n",
    "                     norm=norm);\n",
    "\n",
    "ax2.set_title(\"Simulated CT slice after automatic registration\");\n",
    "imgplot2 = ax2.imshow(test_fibre_in_centre,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "comp_equalized = compare_images(reference_fibre_in_centre, test_fibre_in_centre, method='checkerboard');\n",
    "ax3.set_title(\"Checkboard comparison between\\n\" + \n",
    "              \"the reference and simulated images\\nZNCC: \" + \n",
    "              \"{:.2f}\".format(100.0 * np.mean(np.multiply(reference_fibre_in_centre, test_fibre_in_centre))));\n",
    "imgplot3 = ax3.imshow(comp_equalized,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "plt.savefig('plots/Fibre_in_centre_CT_slices_before_noise.pdf');\n",
    "plt.savefig('plots/Fibre_in_centre_CT_slices_before_noise.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fibre in the centre of the CT slices](plots/Fibre_in_centre_CT_slices_before_noise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimisation of the Poisson noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fitnessFunctionNoise(x):\n",
    "    global best_fitness;\n",
    "    global best_fitness_id;\n",
    "    global prefix;\n",
    "    \n",
    "    bias = x[0];\n",
    "    gain = x[1];\n",
    "    scale = x[2];\n",
    "\n",
    "    # Poisson noise\n",
    "    map = (normalised_projections_ROI + (bias + 1)) * gain;\n",
    "    temp = np.random.poisson(map).astype(float);\n",
    "    temp /= gain;\n",
    "    temp -= bias + 1;\n",
    "    \n",
    "    # Noise map\n",
    "    noise_map = normalised_projections_ROI - temp;\n",
    "    noise_map *= scale;\n",
    "    noisy_image = normalised_projections_ROI + noise_map;\n",
    "\n",
    "    # Compute the standard deviation of the pixel values in the ROI extracted from the simulated image with noise\n",
    "    noisy_image_noise_ROI_stddev = 0;\n",
    "    for y in range(noisy_image.shape[0]):\n",
    "        noisy_image_noise_ROI_stddev += noisy_image[y].std();\n",
    "    noisy_image_noise_ROI_stddev /= noisy_image.shape[0];\n",
    "\n",
    "    # Difference of std dev between the reference and the simulated image\n",
    "    diff = reference_noise_ROI_stddev - noisy_image_noise_ROI_stddev;\n",
    "    objective = diff * diff;\n",
    "    \n",
    "    # The block below is not necessary for the registration.\n",
    "    # It is used to save the data to create animations.\n",
    "    if best_fitness > objective:\n",
    "        best_fitness = objective;\n",
    "    \n",
    "        # Save the simulated CT slice\n",
    "        saveMHA(\"outputs/\" + prefix + \"noisy_image_\" + str(best_fitness_id) + \".mha\",\n",
    "                noisy_image,\n",
    "                [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "\n",
    "        np.savetxt(\"outputs/\" + prefix + str(best_fitness_id) + \".dat\", [bias, gain, scale], header='bias, gain, scale');\n",
    "        \n",
    "        best_fitness_id += 1;\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The registration has already been performed. Load the results.\n",
    "if os.path.isfile(\"outputs/poisson-noise.dat\"):\n",
    "    temp = np.loadtxt(\"outputs/poisson-noise.dat\");\n",
    "    bias = temp[0];\n",
    "    gain = temp[1];\n",
    "    scale = temp[2];\n",
    "\n",
    "# Perform the registration using CMA-ES\n",
    "else:\n",
    "\n",
    "    # Extract a ROI from the reference where no object is\n",
    "    reference_noise_ROI = copy.deepcopy(reference_normalised_projections[450:550,0:125]);\n",
    "\n",
    "    saveMHA(\"outputs/reference_noise_ROI.mha\",\n",
    "           reference_noise_ROI,\n",
    "           [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "\n",
    "    # Compute the standard deviation of the pixel values in the ROI extracted from the reference\n",
    "    reference_noise_ROI_stddev = 0;\n",
    "    for y in range(reference_noise_ROI.shape[0]):\n",
    "        reference_noise_ROI_stddev += reference_noise_ROI[y].std();\n",
    "    reference_noise_ROI_stddev /= reference_noise_ROI.shape[0];\n",
    "\n",
    "    # Copy the simulated projection in a temporary variable\n",
    "    temp = copy.deepcopy(normalised_projections);\n",
    "    temp.shape = reference_normalised_projections.shape\n",
    "\n",
    "    # Extract the corresponding ROI\n",
    "    normalised_projections_ROI = temp[450:550,0:125];\n",
    "\n",
    "    saveMHA(\"outputs/normalised_projections_ROI.mha\",\n",
    "           normalised_projections_ROI,\n",
    "           [pixel_spacing_in_mm, angular_step, pixel_spacing_in_mm]);\n",
    "    \n",
    "    # Initialise the values\n",
    "    bias = 0.0;\n",
    "    gain = 255.0;\n",
    "    scale = 1;\n",
    "\n",
    "    x0 = [bias, gain, scale];\n",
    "\n",
    "    bounds = [\n",
    "        [-1.0,   0.0, 0.0],\n",
    "        [ 5.0, 255.0, 255.0]\n",
    "    ];\n",
    "\n",
    "    opts = cma.CMAOptions()\n",
    "    opts.set('tolfun', 1e-8);\n",
    "    opts['tolx'] = 1e-8;\n",
    "    opts['bounds'] = bounds;\n",
    "    opts['CMA_stds'] = [1, 10, 10];\n",
    "\n",
    "    best_fitness = sys.float_info.max;\n",
    "    best_fitness_id = 0;\n",
    "    prefix = \"poisson-noise_\";\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.25, opts);\n",
    "    es.optimize(fitnessFunctionNoise);\n",
    "\n",
    "    bias = es.result.xbest[0];\n",
    "    gain = es.result.xbest[1];\n",
    "    scale = es.result.xbest[2];\n",
    "\n",
    "    np.savetxt(\"outputs/poisson-noise.dat\", [bias, gain, scale], header='bias, gain, scale');\n",
    "    \n",
    "    # Release memory\n",
    "    del es;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Noise parameters: \", bias, gain, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply the result of the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate the corresponding CT aquisition\n",
    "simulated_sinogram, normalised_projections, raw_projections_in_keV = simulateSinogram(sigma_set, k_set, label_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reconstruct the CT slice\n",
    "simulated_CT = tomopy.recon(simulated_sinogram,\n",
    "                            theta_rad,\n",
    "                            center=rot_center,\n",
    "                            sinogram_order=False,\n",
    "                            algorithm='gridrec',\n",
    "                            filter_name='shepp',\n",
    "                            ncore=40)[0];\n",
    "normalised_simulated_CT = standardisation(simulated_CT);\n",
    "profile_test_whole_image_with_Poisson_noise = copy.deepcopy(np.diag(simulated_CT[offset1:offset2, offset1:offset2]));\n",
    "\n",
    "# Compute the ZNCC\n",
    "print(\"ZNCC noise registration:\",\n",
    "      \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm = cm.colors.Normalize(vmax=1.25, vmin=-0.5)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('CT slice with fibres after the registration')\n",
    "\n",
    "ax1.set_title(\"Reference image\");\n",
    "imgplot1 = ax1.imshow(normalised_reference_CT, cmap=\"gray\", \n",
    "                     norm=norm);\n",
    "\n",
    "ax2.set_title(\"Simulated CT slice after automatic registration\");\n",
    "imgplot2 = ax2.imshow(normalised_simulated_CT,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "comp_equalized = compare_images(normalised_reference_CT, normalised_simulated_CT, method='checkerboard');\n",
    "ax3.set_title(\"Checkboard comparison between\\n\" + \n",
    "              \"the reference and simulated images\\nZNCC: \" + \n",
    "              \"{:.2f}\".format(100.0 * np.mean(np.multiply(normalised_reference_CT, normalised_simulated_CT))));\n",
    "imgplot3 = ax3.imshow(comp_equalized,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "plt.savefig('plots/Fibre_in_centre_CT_slices_after_noise.pdf');\n",
    "plt.savefig('plots/Fibre_in_centre_CT_slices_after_noise.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CT slice with fibres after the registration](plots/Fibre_in_centre_CT_slices_after_noise.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fibre_in_centre      = np.array(copy.deepcopy(simulated_CT[cylinder_position_in_centre_of_slice[1] - roi_length:cylinder_position_in_centre_of_slice[1] + roi_length, cylinder_position_in_centre_of_slice[0] - roi_length:cylinder_position_in_centre_of_slice[0] + roi_length]));\n",
    "profile_test_with_Poisson_noise = copy.deepcopy(np.diag(test_fibre_in_centre));\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Diagonal profile of the fibre in the centre of the reference CT and\\nthe simulated CT slice without and with Poisson noise\")\n",
    "plt.plot(profile_reference, label=\"Reference\");\n",
    "plt.plot(profile_test_without_Poisson_noise, label=\"Simulation without Poisson noise\");\n",
    "plt.plot(profile_test_with_Poisson_noise, label=\"Simulation with Poisson noise\");\n",
    "plt.legend();\n",
    "\n",
    "plt.savefig('plots/profiles.pdf');\n",
    "plt.savefig('plots/profiles.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagonal profile of the fibre in the centre of the reference CT](plots/profiles.png)\n",
    "\n",
    "## Results in terms of linear attenuation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the ROI size to focus on a single fibre and its surrounding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_length = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_fibre_in_centre = np.array(copy.deepcopy(reference_CT[cylinder_position_in_centre_of_slice[1] - roi_length:cylinder_position_in_centre_of_slice[1] + roi_length, cylinder_position_in_centre_of_slice[0] - roi_length:cylinder_position_in_centre_of_slice[0] + roi_length]));\n",
    "test_fibre_in_centre = np.array(copy.deepcopy(simulated_CT[cylinder_position_in_centre_of_slice[1] - roi_length:cylinder_position_in_centre_of_slice[1] + roi_length, cylinder_position_in_centre_of_slice[0] - roi_length:cylinder_position_in_centre_of_slice[0] + roi_length]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA(\"outputs/reference_fibre_in_centre.mha\", reference_fibre_in_centre, [pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "saveMHA(\"outputs/test_fibre_in_centre.mha\", test_fibre_in_centre, [pixel_spacing_in_mm, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a circular binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circular_mask(h, w, center=None, radius=None):\n",
    "\n",
    "    if center is None: # use the middle of the image\n",
    "        center = (int(w/2), int(h/2))\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return np.array(mask, dtype=bool);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create the binary masks for the core, fibre and matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMasks(mask_shape):\n",
    "    fibre_radius_in_px = fibre_radius / pixel_spacing_in_micrometre\n",
    "    core_radius_in_px = core_radius / pixel_spacing_in_micrometre\n",
    "\n",
    "    core_mask = create_circular_mask(mask_shape[1], mask_shape[0], None, core_radius_in_px);\n",
    "\n",
    "    fibre_mask = create_circular_mask(mask_shape[1], mask_shape[0], None, fibre_radius_in_px);\n",
    "    matrix_mask = np.logical_not(fibre_mask);\n",
    "\n",
    "    #fibre_mask = np.subtract(fibre_mask, core_mask);\n",
    "    fibre_mask = np.bitwise_xor(fibre_mask, core_mask);\n",
    "\n",
    "    #TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
    "\n",
    "    return core_mask, fibre_mask, matrix_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary masks for the core, fibre and matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_shape = reference_fibre_in_centre.shape;\n",
    "core_mask, fibre_mask, matrix_mask = createMasks(mask_shape);\n",
    "\n",
    "core_mask = ndimage.binary_erosion(core_mask).astype(core_mask.dtype);\n",
    "\n",
    "for i in range(4):\n",
    "    fibre_mask = ndimage.binary_erosion(fibre_mask).astype(fibre_mask.dtype);\n",
    "    matrix_mask = ndimage.binary_erosion(matrix_mask, border_value=1).astype(matrix_mask.dtype);\n",
    "\n",
    "core_mask.shape = [core_mask.shape[0], core_mask.shape[1]]\n",
    "fibre_mask.shape = [fibre_mask.shape[0], fibre_mask.shape[1]]\n",
    "matrix_mask.shape = [matrix_mask.shape[0], matrix_mask.shape[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMHA(\"outputs/core_mask.mha\", core_mask.astype(np.uint8), [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "saveMHA(\"outputs/fibre_mask.mha\", fibre_mask.astype(np.uint8), [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);\n",
    "saveMHA(\"outputs/matrix_mask.mha\", matrix_mask.astype(np.uint8), [pixel_spacing_in_mm, pixel_spacing_in_mm, pixel_spacing_in_mm]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = cm.colors.Normalize(vmax=1, vmin=0)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Binary mask for every structure')\n",
    "\n",
    "ax1.set_title(\"W core\");\n",
    "imgplot1 = ax1.imshow(core_mask, cmap=\"gray\", \n",
    "                     norm=norm);\n",
    "\n",
    "ax2.set_title(\"SiC fibre\");\n",
    "imgplot2 = ax2.imshow(fibre_mask,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "ax3.set_title(\"Ti90Al6V4 matrix\");\n",
    "imgplot3 = ax3.imshow(matrix_mask,\n",
    "                     cmap='gray',\n",
    "                     norm=norm);\n",
    "\n",
    "plt.savefig('plots/masks.pdf');\n",
    "plt.savefig('plots/masks.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Binary mask for every structure](plots/masks.png)\n",
    "\n",
    "A function to collect all the $\\mu$ statistics from the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMuStatistics(reference_fibre_in_centre, test_fibre_in_centre, core_mask, fibre_mask, matrix_mask):\n",
    "\n",
    "    data = [];\n",
    "    index = np.nonzero(core_mask);\n",
    "    \n",
    "    data.append([\"Theorical\", \n",
    "                \"Core\", \n",
    "                \"W\", \n",
    "                341.61,\n",
    "                341.61,\n",
    "                341.61,\n",
    "                0.0]);\n",
    "\n",
    "    data.append([\"Experimental\", \n",
    "                \"Core\", \n",
    "                \"W\", \n",
    "                np.min(reference_fibre_in_centre[index]),\n",
    "                np.max(reference_fibre_in_centre[index]),\n",
    "                np.mean(reference_fibre_in_centre[index]),\n",
    "                np.std(reference_fibre_in_centre[index])]);\n",
    "    \n",
    "    data.append([\"Simulated\", \n",
    "                \"Core\", \n",
    "                \"W\", \n",
    "                np.min(test_fibre_in_centre[index]),\n",
    "                np.max(test_fibre_in_centre[index]),\n",
    "                np.mean(test_fibre_in_centre[index]),\n",
    "                np.std(test_fibre_in_centre[index])]);\n",
    "\n",
    "    index = np.nonzero(fibre_mask);\n",
    "\n",
    "    data.append([\"Theorical\", \n",
    "                \"Fibre\", \n",
    "                \"SiC\", \n",
    "                2.736,\n",
    "                2.736,\n",
    "                2.736,\n",
    "                0.0]);\n",
    "    \n",
    "    data.append([\"Experimental\", \n",
    "                \"Fibre\", \n",
    "                \"SiC\", \n",
    "                np.min(reference_fibre_in_centre[index]),\n",
    "                np.max(reference_fibre_in_centre[index]),\n",
    "                np.mean(reference_fibre_in_centre[index]),\n",
    "                np.std(reference_fibre_in_centre[index])]);\n",
    "    \n",
    "    data.append([\"Simulated\", \n",
    "                \"Fibre\", \n",
    "                \"SiC\", \n",
    "                np.min(test_fibre_in_centre[index]),\n",
    "                np.max(test_fibre_in_centre[index]),\n",
    "                np.mean(test_fibre_in_centre[index]),\n",
    "                np.std(test_fibre_in_centre[index])]);\n",
    "\n",
    "    index = np.nonzero(matrix_mask);\n",
    "    data.append([\"Theorical\", \n",
    "                \"Matrix\", \n",
    "                \"Ti90Al6V4\", \n",
    "                13.1274,\n",
    "                13.1274,\n",
    "                13.1274,\n",
    "                0.0]);\n",
    "\n",
    "    data.append([\"Experimental\", \n",
    "                \"Matrix\", \n",
    "                \"Ti90Al6V4\", \n",
    "                np.min(reference_fibre_in_centre[index]),\n",
    "                np.max(reference_fibre_in_centre[index]),\n",
    "                np.mean(reference_fibre_in_centre[index]),\n",
    "                np.std(reference_fibre_in_centre[index])]);\n",
    "    \n",
    "    data.append([\"Simulated\", \n",
    "                \"Matrix\", \n",
    "                \"Ti90Al6V4\", \n",
    "                np.min(test_fibre_in_centre[index]),\n",
    "                np.max(test_fibre_in_centre[index]),\n",
    "                np.mean(test_fibre_in_centre[index]),\n",
    "                np.std(test_fibre_in_centre[index])]);\n",
    "    \n",
    "    return pd.DataFrame(data,\n",
    "            index=None,\n",
    "            columns=['CT', 'Structure', \"Composition\", 'min', 'max', 'mean', 'stddev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataframe with all the values and display it as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getMuStatistics(reference_fibre_in_centre, test_fibre_in_centre, core_mask, fibre_mask, matrix_mask);\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the CAD models and plot them in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvxr.saveSTLfile(\"fibre\", \"outputs/final_SiC_fibres.stl\");\n",
    "gvxr.saveSTLfile(\"core\",  \"outputs/final_W_cores.stl\");\n",
    "gvxr.saveSTLfile(\"matrix\", \"outputs/final_Ti90Al6V4_matrix.stl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"outputs/centroids.dat\", centroid_set);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the STL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibre_mesh = mesh.Mesh.from_file('outputs/final_SiC_fibres.stl')\n",
    "core_mesh = mesh.Mesh.from_file('outputs/final_W_cores.stl')\n",
    "matrix_mesh = mesh.Mesh.from_file('outputs/final_Ti90Al6V4_matrix.stl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix their orientation for the 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibre_mesh.rotate([1, 0.0, 0.0], math.radians(90))\n",
    "core_mesh.rotate([1, 0.0, 0.0], math.radians(90))\n",
    "matrix_mesh.rotate([1, 0.0, 0.0], math.radians(90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "axes = mplot3d.Axes3D(figure, azim=30, elev=40, auto_add_to_figure=False)\n",
    "figure.add_axes(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the vectors to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes.add_collection3d(mplot3d.art3d.Poly3DCollection(matrix_mesh.vectors, facecolors='#7fc97f', linewidths=1, alpha=0.1))\n",
    "axes.add_collection3d(mplot3d.art3d.Poly3DCollection(fibre_mesh.vectors, facecolors='#beaed4', linewidths=1, alpha=0.3))\n",
    "axes.add_collection3d(mplot3d.art3d.Poly3DCollection(core_mesh.vectors, facecolors='#fdc086', linewidths=1, alpha=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto scale to the mesh size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = matrix_mesh.points.flatten()\n",
    "axes.auto_scale_xyz(scale, scale, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Final CAD models (in mm)\");\n",
    "plt.savefig('plots/CAD_models.pdf')\n",
    "plt.savefig('plots/CAD_models.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final CAD models (in mm)\n",
    "\n",
    "![Final CAD models in 3D](./plots/CAD_models.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
