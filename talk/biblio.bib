@Book{Als-Nielsen2011,
  title     = {Elements of Modern X-Ray Physics},
  publisher = {John Wiley \& Sons},
  year      = {2011},
  author    = {Als-Nielsen, J and Mcmorrow, D},
  isbn      = {0470973943},
  date      = {2011-03-25},
  ean       = {9780470973943},
  file      = {:Als-Nielsen2011_book.pdf:PDF},
  pagetotal = {436},
  url       = {https://www.ebook.de/de/product/14773530/des_mcmorrow_als_nielsen_elements_of_modern_x_ray_physics.html},
}

@article{JOSKOWICZ201854,
    title = {Automatic segmentation variability estimation with segmentation priors},
    journal = {Medical Image Analysis},
    volume = {50},
    pages = {54-64},
    year = {2018},
    issn = {1361-8415},
    doi = {10.1016/j.media.2018.08.006},
    author = {L. Joskowicz and D. Cohen and N. Caplan and J. Sosna},
    keywords = {Segmentation uncertainty estimation, Segmentation priors, Observer variability},
    abstract = {Purpose
    Segmentations produced manually by experts or by algorithms are subject to variability, as they depend on many factors, e.g., the structure of interest, the resolution, contrast and quality of the images, and the expert experience or the algorithmic method. To properly assess the quality of these segmentations, it is thus essential to quantify their variability. However, obtaining reference variability ground truth requires several observers to manually delineate structures, which is time-consuming and impractical.
    Methods
    We describe a new comprehensive formal framework for segmentation evaluation and variability estimation without ground truth and a generic method for automatic segmentation variability estimation based on segmentation priors and multivariate sensitivity analysis. The method inputs the image scan and a user-validated segmentation of the structure of interest and uses predefined segmentation priors to compute a variability estimation around the given segmentation. The segmentation priors are combined with an integrator function whose sensitivity around the given segmentation is the segmentation variability.
    Results
    We validate our methods with two studies. The first study establishes the reference manual delineation variability. Eleven radiologists with varying levels of expertise manually delineated the contours of liver tumors, lung tumors, kidneys, and brain hematomas on 2,835 delineations from 18 CT scans. The relative delineation volume variability ranges are 51 [−24,+27]\% for liver tumors, 56 [−25,+31]\% for lung tumors, 25 [−12,+13]\% for kidney contours, and 53 [−24,+29]\% brain hematomas. The second study compares the estimated segmentation variability results to this reference data. The mean volume variability difference of the delineation is <6\%, with a Dice similarity coefficient of >70\% with respect to the mean manual delineation variability data.
    Conclusions
    Reliable segmentation variability estimation with no ground truth enables the establishment of a proper observer variability reference. The segmentation variability should be taken into account when setting reference standards for clinical decisions based on volumetric measurements and when evaluating segmentation algorithms.}
}

@article{https://doi.org/10.1107/S1600577516015812,
author = {Jailin, Clément and Buffière, Jean-Yves and Hild, François and Poncelet, Martin and Roux, Stéphane},
title = {On the use of flat-fields for tomographic reconstruction},
journal = {Journal of Synchrotron Radiation},
volume = {24},
number = {1},
pages = {220-231},
keywords = {flat-field normalization, artifact corrections, computed tomography},
doi = {10.1107/S1600577516015812},
abstract = {Seeking for quantitative tomographic images, it is of utmost importance to limit reconstruction artifacts. Detector imperfections, inhomogeneity of the incident beam, as classically observed in synchrotron beamlines, and their variations in time are a major cause of reconstruction bias such as `ring artifacts'. The present study aims at proposing a faithful estimate of the incident beam local intensity for each acquired projection during a scan, without revisiting the process of data acquisition itself. Actual flat-fields (acquired without specimen in the beam) and sinogram borders (when the specimen is present), which are not masked during the scan, are exploited to construct a suited instantaneous detector-wide flat-field. The proposed treatment is fast and simple. Its performance is assessed on a real scan acquired at ESRF ID19 beamline. Different criteria are used including residuals, i.e. difference between projections of reconstruction and actual projections. All confirm the benefit of the proposed procedure.},
year = {2017}
}


@article{ENDRIZZI201888,
	abstract = {X-ray imaging is a standard tool for the non-destructive inspection of the internal structure of samples. It finds application in a vast diversity of fields: medicine, biology, many engineering disciplines, palaeontology and earth sciences are just few examples. The fundamental principle underpinning the image formation have remained the same for over a century: the X-rays traversing the sample are subjected to different amount of absorption in different parts of the sample. By means of phase-sensitive techniques it is possible to generate contrast also in relation to the phase shifts imparted by the sample and to extend the capabilities of X-ray imaging to those details that lack enough absorption contrast to be visualised in conventional radiography. A general overview of X-ray phase contrast imaging techniques is presented in this review, along with more recent advances in this fast evolving field and some examples of applications.},
	author = {Endrizzi, Marco},
	doi = {10.1016/j.nima.2017.07.036},
	issn = {0168-9002},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {X-ray; Phase-contrast; Imaging},
	note = {Radiation Imaging Techniques and Applications},
	pages = {88--98},
	title = {X-ray phase-contrast imaging},
	volume = {878},
	year = {2018}
}

@Article{Withers2021,
  author    = {Withers, P J and Bouman, C and Carmignato, S and Cnudde, V and Grimaldi, D and Hagen, C K and Maire, E and Manley, M and Du Plessis, A and Stock, S R},
  journal   = {Nature Reviews Methods Primers},
  title     = {X-ray computed tomography},
  year      = {2021},
  month     = {feb},
  number    = {1},
  volume    = {1},
  doi       = {10.1038/s43586-021-00015-4},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Tekawade2019,
  author    = {Tekawade, A and Sforzo, B A and Matusik, K E and Kastengren, A L and Powell, C F},
  booktitle = {Developments in X-Ray Tomography {XII}},
  title     = {High-fidelity geometry generation from {CT} data using convolutional neural networks},
  year      = {2019},
  editor    = {Bert Müller and Ge Wang},
  month     = {sep},
  publisher = {{SPIE}},
  doi       = {10.1117/12.2540442},
}

@article{Liu2020,
author = {Liu, Z and Bicer, T and Kettimuthu, R and Gursoy, D and De Carlo, F and Foster, I},
journal = {J. Opt. Soc. Am. A},
number = {3},
pages = {422--434},
publisher = {OSA},
title = {Tomo{GAN}: low-dose synchrotron x-ray tomography with generative adversarial networks: discussion},
volume = {37},
month = {Mar},
year = {2020},
doi = {10.1364/JOSAA.375595},
}


@inproceedings{Rogelj2001,
author = {Peter Rogelj and Stanislav Kovacic},
title = {{Similarity measures for nonrigid registration}},
volume = {4322},
booktitle = {Medical Imaging 2001: Image Processing},
editor = {Milan Sonka and Kenneth M. Hanson},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {569 -- 578},
abstract = {Non-rigid multimodal registration requires similarity measure with two important properties: locality and multi- modality. Unfortunately all commonly used multimodal similarity measures are inherently global and cannot be directly used to estimate local image properties. We have derived a local similarity measure based on joint entropy, which can operate on extremely small image regions, e.g. individual voxels. Using such small image regions reflects in higher sensitivity to noise and partial volume voxels, consequently reducing registration speed and accuracy. To cope with these problems we enhance the similarity measure with image segmentation. Image registration and image segmentation are related tasks, as segmentation can be performed by registering an image to a pre-segmented reference image, while on the other hand registration yields better results when the images are pre-segmented. Because of these interdependences it was anticipated that simultaneous application of registration and segmentation should improve registration as well as segmentation results. Several experiments based on synthetic images were performed to test this assumption. The results obtained show that our method can improve the registration accuracy and reduce the required number of registration steps.},
year = {2001},
doi = {10.1117/12.431131},
}


@article{RAZLIGHI2013977,
title = {Evaluating similarity measures for brain image registration},
journal = {Journal of Visual Communication and Image Representation},
volume = {24},
number = {7},
pages = {977-987},
year = {2013},
issn = {1047-3203},
doi = {10.1016/j.jvcir.2013.06.010},
author = {Q. R. Razlighi and N. Kehtarnavaz and S. Yousefi},
keywords = {Brain image registration, Similarity measures, Spatial mutual information, Normalized spatial mutual information, Comparison of similarity measures},
abstract = {Evaluation of similarity measures for image registration is a challenging problem due to its complex interaction with the underlying optimization, regularization, image type and modality. We propose a single performance metric, named robustness, as part of a new evaluation method which quantifies the effectiveness of similarity measures for brain image registration while eliminating the effects of the other parts of the registration process. We show empirically that similarity measures with higher robustness are more effective in registering degraded images and are also more successful in performing intermodal image registration. Further, we introduce a new similarity measure, called normalized spatial mutual information, for 3D brain image registration whose robustness is shown to be much higher than the existing ones. Consequently, it tolerates greater image degradation and provides more consistent outcomes for intermodal brain image registration.}
}

@article{ZITOVA2003977,
title = {Image registration methods: a survey},
journal = {Image and Vision Computing},
volume = {21},
number = {11},
pages = {977-1000},
year = {2003},
issn = {0262-8856},
doi = {10.1016/S0262-8856(03)00137-9},
author = {Barbara Zitová and Jan Flusser},
keywords = {Image registration, Feature detection, Feature matching, Mapping function, Resampling},
abstract = {This paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlaying images (two or more) of the same scene taken at different times, from different viewpoints, and/or by different sensors. The registration geometrically align two images (the reference and sensed images). The reviewed approaches are classified according to their nature (area-based and feature-based) and according to four basic steps of image registration procedure: feature detection, feature matching, mapping function design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned in the paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is to provide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas.}
}@inproceedings{auger2005restart,
  title={A restart {CMA} evolution strategy with increasing population size},
  author={Auger, A. and Hansen, N.},
  booktitle={The 2005 {IEEE} International Congress on Evolutionary Computation ({CEC}'05)},
  editor = {B. McKay and others},
  volume={2},
  pages={1769--1776},
  year={2005}
}

@inproceedings{hansen2009bbi,
  author={Hansen, N.},
  title={Benchmarking a {BI}-Population {CMA-ES} on the {BBOB}-2009 Function Testbed},
  booktitle={Workshop Proceedings of the {GECCO} Genetic and Evolutionary Computation Conference},
  year={2009},
  month = {July},
  publisher = {ACM},
  pages = {2389--2395}
}

@PhDThesis{Mustafa:Thesis:2020,
    author     =     {Mustafa Haiderbhai},
    title     =     {Generating Synthetic X-rays Using Generative Adversarial Networks},
    school     =     {University of Ottawa},
    address     =     {Canada},
    year     =     {2020},
    doi = {10.20381/ruor-25316}
    }

@INPROCEEDINGS{9175420,
  author={Haiderbhai, Mustafa and Ledesma, Sergio and Navab, Nassir and Fallavollita, Pascal},
  booktitle={2020 42nd Annual International Conference of the IEEE Engineering in Medicine   Biology Society (EMBC)}, 
  title={Generating X-ray Images from Point Clouds Using Conditional Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1588-1591},
  doi={10.1109/EMBC44109.2020.9175420}}

@article{Haiderbhai2020,
	risfield_0_da = {2020/06/01},
	abstract = {We propose a novel methodology for generating synthetic X-rays from 2D RGB images. This method creates accurate simulations for use in non-diagnostic visualization problems where the only input comes from a generic camera. Traditional methods are restricted to using simulation algorithms on 3D computer models. To solve this problem, we propose a method of synthetic X-ray generation using conditional generative adversarial networks (CGANs).},
	author = {Haiderbhai, Mustafa and Ledesma, Sergio and Lee, Sing Chun and Seibold, Matthias and F{\"u}rnstahl, Phillipp and Navab, Nassir and Fallavollita, Pascal},
	doi = {10.1007/s11548-020-02159-2},
	issn = {1861-6429},
	journal = {International Journal of Computer Assisted Radiology and Surgery},
	number = {6},
	pages = {973--980},
	title = {pix2xray: converting {RGB} images into X-rays using generative adversarial networks},
	volume = {15},
	year = {2020}
}

@TechReport{iso10360-11,
  author      = {{ISO Central Secretary}},
  institution = {International Organization for Standardization},
  title       = {Geometrical product specifications ({GPS}) -- {A}cceptance and reverification tests for coordinate measuring systems ({CMS}) -- {P}art 11: {CMS}s using the principle of X-ray computed tomography ({CT})},
  year        = {2021},
  address     = {Geneva, CH},
  number      = {ISO/IEC 10360-11:2021},
  type        = {Standard},
  file        = {:iso10360-11.pdf:PDF},
  language    = {en},
  shorttitle  = {{ISO}/{DIS} 10360-11},
}

@article{Monin2004,
    author = {Monnin, P. and Bulling, S. and Hoszowska, J. and Valley, J. F. and Meuli, R. and Verdun, F. R.},
    title = {Quantitative characterization of edge enhancement in phase contrast x-ray imaging},
    journal = {Medical Physics},
    year = 2004,
    month = jun,
    volume = 31,
    number = 6,
    pages = {1372-1383},
    doi = {10.1118/1.1755568},
    PMID = {15259641},
}

@article{Peterzol2005,
author = {Peterzol, A. and Olivo, A. and Rigon, L. and Pani, S. and Dreossi, D.},
title = {The effects of the imaging system on the validity limits of the ray-optical approach to phase contrast imaging},
journal = {Medical Physics},
volume = {32},
number = {12},
pages = {3617-3627},
keywords = {Radiography, Ancillary equipment, diagnostic radiography, biomedical optical imaging, phantoms, synchrotron radiation, Fresnel diffraction, numerical analysis, Medical imaging, Image sensors, Medical image contrast, Spatial resolution, Medical X-ray imaging, X-ray detectors, X-ray imaging, X-ray diffraction, Medical image spatial resolution, X-rays},
doi = {10.1118/1.2126207},
abstract = {A theoretical analysis of the x-ray phase contrast imaging and its validation via synchrotron radiation imaging is here presented. Two different mathematical models have been followed: the simpler ray-optical approach and the more rigorous Fresnel-Kirchoff diffraction theory. Subsequently, the conditions upon which the x-ray optical approximation can be used to describe the image formation mechanism have been analyzed, taking into account also the effects due to the finite source size and detector resolution. It is possible to demonstrate that the ray-optics results can also be obtained by opportunely developing the diffraction formalism only with some restrictions on the spatial frequencies present in the final image, without any limitation on the maximum phase shift. The conditions allowing the use of the simplified ray-optical approach to describe the phase contrast images have been here defined and their validation has been proved by means of computer simulations and phantom experiments.},
year = {2005}
}

@article{Inselberg1985,
    abstract = {By means of Parallel Coordinates planar “graphs” of multivariate relations are obtained. Certain properties of the relationship correspond tothe geometrical properties of its graph. On the plane a point ←→ line duality with several interesting properties is induced. A new duality betweenbounded and unbounded convex sets and hstars (a generalization of hyperbolas) and between Convex Unions and Intersections is found. This motivates some efficient Convexity algorithms and other results inComputational Geometry. There is also a suprising “cusp” ←→ “inflection point” duality. The narrative ends with a preview of the corresponding results inRN.},
    author = {Inselberg, Alfred},
    doi = {10.1007/BF01898350},
    issn = {1432-2315},
    journal = {The Visual Computer},
    number = {2},
    pages = {69--91},
    title = {{The plane with parallel coordinates}},
    volume = {1},
    year = {1985}
}

@ARTICLE{7192677,
  author={Johansson, Jimmy and Forsell, Camilla},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research},
  year={2016},
  volume={22},
  number={1},
  pages={579-588},
  doi={10.1109/TVCG.2015.2466992}
}

@article{FREUD2006175,
title = {Fast and robust ray casting algorithms for virtual X-ray imaging},
journal = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
volume = {248},
number = {1},
pages = {175-180},
year = {2006},
issn = {0168-583X},
doi = {10.1016/j.nimb.2006.03.009},
author = {N. Freud and P. Duvauchelle and J.M. Létang and D. Babot},
keywords = {X-ray imaging, Deterministic simulation, Ray casting, -Buffer, Robustness},
abstract = {Deterministic calculations based on ray casting techniques are known as a powerful alternative to the Monte Carlo approach to simulate X- or γ-ray imaging modalities (e.g. digital radiography and computed tomography), whenever computation time is a critical issue. One of the key components, from the viewpoint of computing resource expense, is the algorithm which determines the path length travelled by each ray through complex 3D objects. This issue has given rise to intensive research in the field of 3D rendering (in the visible light domain) during the last decades. The present work proposes algorithmic solutions adapted from state-of-the-art computer graphics to carry out ray casting in X-ray imaging configurations. This work provides an algorithmic basis to simulate direct transmission of X-rays, as well as scattering and secondary emission of radiation. Emphasis is laid on the speed and robustness issues. Computation times are given in a typical case of radiography simulation.}
}

@article{CMA-ES,
    author = {Hansen, Nikolaus and Ostermeier, Andreas},
    title = "{Completely Derandomized Self-Adaptation in Evolution Strategies}",
    journal = {Evolutionary Computation},
    volume = {9},
    number = {2},
    pages = {159-195},
    year = {2001},
    month = {06},
    abstract = "{This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equiv-alent to applying a general, linear problem encoding.The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigor-ously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps.Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is ob-served. On moderately mis-scaled functions a speed up factor of three to ten can be expected.}",
    issn = {1063-6560},
    doi = {10.1162/106365601750190398},
}

@Article{Hiller2016_pe,
  author    = {Hiller, J and Hornberger, P},
  journal   = {Precision Engineering},
  title     = {Measurement accuracy in X-ray computed tomography metrology: Toward a systematic analysis of interference effects in tomographic imaging},
  year      = {2016},
  month     = {jul},
  pages     = {18--32},
  volume    = {45},
  doi       = {10.1016/j.precisioneng.2015.12.003},
  file      = {:Hiller2016_pe.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@ARTICLE{4767964,
  author={Illingworth, J. and Kittler, J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={The Adaptive Hough Transform}, 
  year={1987},
  volume={PAMI-9},
  number={5},
  pages={690-698},
  doi={10.1109/TPAMI.1987.4767964}
}

@Article{Kovacs2015_gm,
  author    = {Kov{\'{a}}cs, I and V{\'{a}}rady, T and Salvi, P},
  journal   = {Graphical Models},
  title     = {Applying geometric constraints for perfecting {CAD} models in reverse engineering},
  year      = {2015},
  month     = {nov},
  pages     = {44--57},
  volume    = {82},
  doi       = {10.1016/j.gmod.2015.06.002},
  file      = {:Kovacs2015_gm.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Stayman2012_tmi,
  author    = {Stayman, J W and Otake, Y and Prince, J L and Khanna, A J and Siewerdsen, J H},
  journal   = {{IEEE} Transactions on Medical Imaging},
  title     = {Model-Based Tomographic Reconstruction of Objects Containing Known Components},
  year      = {2012},
  month     = {oct},
  number    = {10},
  pages     = {1837--1848},
  volume    = {31},
  doi       = {10.1109/tmi.2012.2199763},
  file      = {:Stayman2012_tmi.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Thompson2016_mst,
  author    = {Thompson, A and Maskery, I and Leach, R K},
  journal   = {Measurement Science and Technology},
  title     = {X-ray computed tomography for additive manufacturing: a review},
  year      = {2016},
  month     = {jun},
  number    = {7},
  pages     = {072001},
  volume    = {27},
  doi       = {10.1088/0957-0233/27/7/072001},
  file      = {:Thompson2016_mst.pdf:PDF},
  publisher = {{IOP} Publishing},
}

@article{VIDAL2005333,
title = {Investigation of artefact sources in synchrotron microtomography via virtual X-ray imaging},
journal = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
volume = {234},
number = {3},
pages = {333-348},
year = {2005},
issn = {0168-583X},
doi = {10.1016/j.nimb.2005.02.003},
author = {F.P. Vidal and J.M. Létang and G. Peix and P. Cloetens},
keywords = {X-ray microtomography, Artefact, Deterministic simulation (ray-tracing), Monte Carlo method, Phase contrast, Modulation transfer function},
abstract = {Qualitative and quantitative use of volumes reconstructed by computed tomography (CT) can be compromised due to artefacts which corrupt the data. This article illustrates a method based on virtual X-ray imaging to investigate sources of artefacts which occur in microtomography using synchrotron radiation. In this phenomenological study, different computer simulation methods based on physical X-ray properties, eventually coupled with experimental data, are used in order to compare artefacts obtained theoretically to those present in a volume acquired experimentally, or to predict them for a particular experimental setup. The article begins with the presentation of a synchrotron microtomographic slice of a reinforced fibre composite acquired at the European Synchrotron Radiation Facility (ESRF) containing streak artefacts. This experimental context is used as the motive throughout the paper to illustrate the investigation of some artefact sources. First, the contribution of direct radiation is compared to the contribution of secondary radiations. Then, the effect of some methodological aspects are detailed, including under-sampling, sample and camera misalignment, sample extending outside of the field of view and photonic noise. The effect of harmonic components present in the experimental spectrum are also simulated. Afterwards, detector properties, such as its impulse response or defective pixels, are taken into account. Finally, the importance of phase contrast effects is evaluated. In the last section, this investigation is discussed by putting emphasis on the experimental context which is used throughout this paper.}
}

@inproceedings{Vidal2009TPCG,
  author = {F. P. Vidal and M. Garnier and N. Freud and J. M. L\'etang and N. W. John},
  title = {Simulation of {X-ray} Attenuation on the {GPU}},
  booktitle = {Proceedings of Theory and Practice of Computer Graphics 2009},
  year = 2009,
  pages = {25-32},
  month = jun,
  address = {Cardiff, UK},
  annotation = {Jun~17--19, 2009},
  doi = {10.2312/LocalChapterEvents/TPCG/TPCG09/025-032},
  abstract = {In this paper, we propose to take advantage of computer graphics hardware
	to achieve an accelerated simulation of X-ray transmission imaging,
	and we compare results with a fast and robust software-only implementation.
	The running times of the GPU and CPU implementations are compared
	in different test cases. The results show that the GPU implementation
	with full floating point precision is faster by a factor of about
	60 to 65 than the CPU implementation, without any significant loss
	of accuracy. The increase in performance achieved with GPU calculations
	opens up new perspectives. Notably, it paves the way for physically-realistic
	simulation of X-ray imaging in interactive time.},
  keywords = {Physically based modeling, Raytracing, Physics},
  publisher = {Eurographics Association},
  pdf = {./pdf/Vidal2009TPCG.pdf}
}

@inproceedings{Vidal2010EGPoster,
  author = {F. P. Vidal and M. Garnier and N. Freud and J. M. L\'etang and N. W. John},
  title = {Accelerated Deterministic Simulation of X-ray Attenuation Using Graphics Hardware},
  booktitle = {Eurographics 2010 - Poster},
  year = 2010,
  pages = {Poster 5011},
  month = may,
  address = {Norrk"{o}ping, Sweden},
  annotation = {May~3--7, 2010},
  abstract = {In this paper, we propose a deterministic simulation of X-ray transmission imaging on graphics hardware. Only
	the directly transmitted photons are simulated, using the Beer-Lambert law. Our previous attempt to simulate Xray
	attenuation from polygon meshes utilising the GPU showed significant increase of performance, with respect
	to a validated software implementation, without loss of accuracy. However, the simulations were restricted to
	monochromatic X-rays and finite point sources. We present here an extension to our method to perform physically
	more realistic simulations by taking into account polychromatic X-rays and focal spots causing blur.},
  keywords = {Three-Dimensional Graphics and Realism; Raytracing; Physical Sciences and Engineering; Physics},
  publisher = {Eurographics Association},
  pdf = {pdf/Vidal2010EGPoster.pdf}
}

@article{doi:10.1063/1.364374,
	author = {Cl{\oe}tens, P. and Pateyron-Salom{\'e}, M. and Buffi{\`e}re, J. Y. and Peix, G. and Baruchel, J. and Peyrin, F. and Schlenker, M.},
	doi = {10.1063/1.364374},
	journal = {Journal of Applied Physics},
	number = {9},
	pages = {5878--5886},
	title = {Observation of microstructure and damage in materials by phase sensitive radiography and tomography},
	volume = {81},
	year = {1997}
}

@ARTICLE{8943397,
  author={Hehn, Lorenz and Gradl, Regine and Dierolf, Martin and Morgan, Kaye S. and Paganin, David M. and Pfeiffer, Franz},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Model-Based Iterative Reconstruction for Propagation-Based Phase-Contrast X-Ray {CT} including Models for the Source and the Detector}, 
  year={2020},
  volume={39},
  number={6},
  pages={1975-1987},
  doi={10.1109/TMI.2019.2962615}}


@techreport{osti_6016002,
title = {{XCOM}: Photon cross sections on a personal computer},
author = {Berger, M J and Hubbell, J H},
abstract = {A computer program and data base are presented which can be used to calculate, with a personal computer, photon cross sections for scattering, photoelectric absorption and pair production, as well as total attenuation coefficients, in any element, compound or mixture, at energies from 1 keV to 100 GeV.},
url = {https://doi.org/10.2172/6016002},
place = {United States},
year = {1987},
month = {7},
institution = {National Institute of Standards and Technology}
} 

@webpage{XCOM,
    author = {M. J. Berger and J. H. Hubbell and S. M. Seltzer and J. Chang and J. S. Coursey and R. Sukumar and D. S. Zucker and K. Olsen},
    title = {{XCOM}: Photon cross section database},
    year =1998,
    month = mar,
    url={https://www.physics.nist.gov/PhysRefData/Xcom/html/xcom1.html},
}

@article{repository,
    author = {Vidal, Franck P. and Mitchell, Iwan T. and L\'etang, Jean Michel},
    title = {Supplementary Material: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    journal = {Mendeley Data},
    year =2021,
    month = aug,
    doi = {10.17632/r8b5mcrj6j.1}
}

@webpage{10.5281/zenodo.5075298,
    author = {Franck P. Vidal},
    title = {{gVirtualXRay:} source code of the Virtual X-Ray Imaging Library on {GPU}},
    url={https://doi.org/10.5281/zenodo.5075298},
    year =2021,
    month = aug,
    doi = {10.5281/zenodo.5075298}
}

@webpage{10.5281/zenodo.5075378,
    author = {Franck P. Vidal and Iwan T. Mitchell and Jean M. L\'etang},
    title = {Supplementary material: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    url={https://www.doi.org/10.5281/zenodo.5075378},
    year =2021,
    month = aug,
    doi = {10.5281/zenodo.5075378}
}

@webpage{CT2CAD-Fibres-GitHub,
    author = {Franck P. Vidal and Iwan T. Mitchell and Jean M. L\'etang},
    title = {{GitHub} repository: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    url={https://github.com/effepivi/CT2CAD-Fibres},
    year =2021,
    month = aug,
}

@webpage{gVirtualXRay,
    author = {Franck P. Vidal},
    title = {{gVirtualXRay}},
    url={http://gvirtualxray.sourceforge.net/},
    year =2021,
    month = aug,
}

@article{doi:10.1080/10255842.2012.670855,
    author = {Francisco P.M. Oliveira and João Manuel R.S. Tavares},
    title = {Medical image registration: a review},
    journal = {Computer Methods in Biomechanics and Biomedical Engineering},
    volume = {17},
    number = {2},
    pages = {73-93},
    year  = {2014},
    publisher = {Taylor & Francis},
    doi = {10.1080/10255842.2012.670855},
    note ={PMID: 22435355},
}

@InProceedings{10.1007/978-3-030-72699-7_29,
author="Wen, Tianci
and Mihail, Radu P.
and Vidal, Franck P.",
editor="Castillo, Pedro A.
and Jim{\'e}nez Laredo, Juan Luis",
title="3D-2D Registration Using X-Ray Simulation and CMA-ES",
booktitle="Applications of Evolutionary Computation",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="453--468",
abstract="Radiographs of the hand are useful in diagnosing and staging diseases such as rheumatoid arthritis (RA) and other musculoskeletal diseases. Radiographs are projections of the 3D anatomy, with the useful information such as pose and pathology becoming lost in the process. We propose a 3D hand pose recovery method for radiographs of hands using a novel hybrid image registration method. Our pose recovery pipeline consists of aligning a simulated X-ray (digitally reconstructed radiograph) of an articulated phantom mesh model to a real hand radiograph using Covariance Matrix Adaptation Evolution Strategy. Early results demonstrate that our approach works well. Further inquiry is required to evaluate the applicability of our registration approach to other articulated musculoskeletal anatomy.",
isbn="978-3-030-72699-7"
}

@inproceedings {vc.20191265,
booktitle = {Computer Graphics and Visual Computing (CGVC)},
editor = {Vidal, Franck P. and Tam, Gary K. L. and Roberts, Jonathan C.},
title = {{Registration of 3D Triangular Models to 2D X-ray Projections Using Black-box Optimisation and X-ray Simulation}},
author = {Wen, Tianci and Mihail, Radu and Al-maliki, shatha and Letang, Jean and Vidal, Franck},
year = {2019},
publisher = {The Eurographics Association},
ISBN = {978-3-03868-096-3},
DOI = {10.2312/cgvc.20191265},
pages = {105-113}
}


@article{ALLISON2016186,
title = {Recent developments in {G}eant4},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {835},
pages = {186-225},
year = {2016},
issn = {0168-9002},
doi = {10.1016/j.nima.2016.06.125},
author = {J. Allison and K. Amako and J. Apostolakis and P. Arce and M. Asai and T. Aso and E. Bagli and A. Bagulya and S. Banerjee and G. Barrand and B.R. Beck and A.G. Bogdanov and D. Brandt and J.M.C. Brown and H. Burkhardt and Ph. Canal and D. Cano-Ott and S. Chauvie and K. Cho and G.A.P. Cirrone and G. Cooperman and M.A. Cortés-Giraldo and G. Cosmo and G. Cuttone and G. Depaola and L. Desorgher and X. Dong and A. Dotti and V.D. Elvira and G. Folger and Z. Francis and A. Galoyan and L. Garnier and M. Gayer and K.L. Genser and V.M. Grichine and S. Guatelli and P. Guèye and P. Gumplinger and A.S. Howard and I. Hřivnáčová and S. Hwang and S. Incerti and A. Ivanchenko and V.N. Ivanchenko and F.W. Jones and S.Y. Jun and P. Kaitaniemi and N. Karakatsanis and M. Karamitros and M. Kelsey and A. Kimura and T. Koi and H. Kurashige and A. Lechner and S.B. Lee and F. Longo and M. Maire and D. Mancusi and A. Mantero and E. Mendoza and B. Morgan and K. Murakami and T. Nikitina and L. Pandola and P. Paprocki and J. Perl and I. Petrović and M.G. Pia and W. Pokorski and J.M. Quesada and M. Raine and M.A. Reis and A. Ribon and A. {Ristić Fira} and F. Romano and G. Russo and G. Santin and T. Sasaki and D. Sawkey and J.I. Shin and I.I. Strakovsky and A. Taborda and S. Tanaka and B. Tomé and T. Toshito and H.N. Tran and P.R. Truscott and L. Urban and V. Uzhinsky and J.M. Verbeke and M. Verderi and B.L. Wendt and H. Wenzel and D.H. Wright and D.M. Wright and T. Yamashita and J. Yarba and H. Yoshida},
keywords = {High energy physics, Nuclear physics, Radiation, Simulation, Computing},
abstract = {Geant4 is a software toolkit for the simulation of the passage of particles through matter. It is used by a large number of experiments and projects in a variety of application domains, including high energy physics, astrophysics and space science, medical physics and radiation protection. Over the past several years, major changes have been made to the toolkit in order to accommodate the needs of these user communities, and to efficiently exploit the growth of computing power made available by advances in technology. The adaptation of Geant4 to multithreading, advances in physics, detector modeling and visualization, extensions to the toolkit, including biasing and reverse Monte Carlo, and tools for physics and release validation are discussed here.}
}

@article{VIDAL20161,
title = {Development and validation of real-time simulation of X-ray imaging with respiratory motion},
journal = {Computerized Medical Imaging and Graphics},
volume = {49},
pages = {1-15},
year = {2016},
issn = {0895-6111},
doi = {10.1016/j.compmedimag.2015.12.002},
author = {Franck P. Vidal and Pierre-Frédéric Villard},
keywords = {X-ray simulation, Deterministic simulation (ray-tracing), Digitally reconstructed radiograph, Respiration simulation, Medical virtual environment, Imaging guidance, Interventional radiology training},
abstract = {We present a framework that combines evolutionary optimisation, soft tissue modelling and ray tracing on GPU to simultaneously compute the respiratory motion and X-ray imaging in real-time. Our aim is to provide validated building blocks with high fidelity to closely match both the human physiology and the physics of X-rays. A CPU-based set of algorithms is presented to model organ behaviours during respiration. Soft tissue deformation is computed with an extension of the Chain Mail method. Rigid elements move according to kinematic laws. A GPU-based surface rendering method is proposed to compute the X-ray image using the Beer–Lambert law. It is provided as an open-source library. A quantitative validation study is provided to objectively assess the accuracy of both components: (i) the respiration against anatomical data, and (ii) the X-ray against the Beer–Lambert law and the results of Monte Carlo simulations. Our implementation can be used in various applications, such as interactive medical virtual environment to train percutaneous transhepatic cholangiography in interventional radiology, 2D/3D registration, computation of digitally reconstructed radiograph, simulation of 4D sinograms to test tomography reconstruction tools.}
}

@Article{VillarragaGomez2019_pe,
  author    = {Villarraga-G{\'{o}}mez, H and Herazo, E L and Smith, S T},
  journal   = {Precision Engineering},
  title     = {X-ray computed tomography: from medical imaging to dimensional metrology},
  year      = {2019},
  month     = {nov},
  pages     = {544--569},
  volume    = {60},
  doi       = {10.1016/j.precisioneng.2019.06.007},
  file      = {:VillarragaGomez2019_pe.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@ARTICLE{SSIM,
  author={Wang, Z and Bovik, A C and Sheikh, H R  and Simoncelli, E P},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  doi={10.1109/TIP.2003.819861}
}
ansen, Nikolaus and Ostermeier, Andreas},
    title = "{Completely Derandomized Self-Adaptation in Evolution Strategies}",
    journal = {Evolutionary Computation},
    volume = {9},
    number = {2},
    pages = {159-195},
    year = {2001},
    month = {06},
    abstract = "{This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equiv-alent to applying a general, linear problem encoding.The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigor-ously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps.Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is ob-served. On moderately mis-scaled functions a speed up factor of three to ten can be expected.}",
    issn = {1063-6560},
    doi = {10.1162/106365601750190398},
}

@Article{Hiller2016_pe,
  author    = {Hiller, J and Hornberger, P},
  journal   = {Precision Engineering},
  title     = {Measurement accuracy in X-ray computed tomography metrology: Toward a systematic analysis of interference effects in tomographic imaging},
  year      = {2016},
  month     = {jul},
  pages     = {18--32},
  volume    = {45},
  doi       = {10.1016/j.precisioneng.2015.12.003},
  file      = {:Hiller2016_pe.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@ARTICLE{4767964,
  author={Illingworth, J. and Kittler, J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={The Adaptive Hough Transform}, 
  year={1987},
  volume={PAMI-9},
  number={5},
  pages={690-698},
  doi={10.1109/TPAMI.1987.4767964}
}

@Article{Kovacs2015_gm,
  author    = {Kov{\'{a}}cs, I and V{\'{a}}rady, T and Salvi, P},
  journal   = {Graphical Models},
  title     = {Applying geometric constraints for perfecting {CAD} models in reverse engineering},
  year      = {2015},
  month     = {nov},
  pages     = {44--57},
  volume    = {82},
  doi       = {10.1016/j.gmod.2015.06.002},
  file      = {:Kovacs2015_gm.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Stayman2012_tmi,
  author    = {Stayman, J W and Otake, Y and Prince, J L and Khanna, A J and Siewerdsen, J H},
  journal   = {{IEEE} Transactions on Medical Imaging},
  title     = {Model-Based Tomographic Reconstruction of Objects Containing Known Components},
  year      = {2012},
  month     = {oct},
  number    = {10},
  pages     = {1837--1848},
  volume    = {31},
  doi       = {10.1109/tmi.2012.2199763},
  file      = {:Stayman2012_tmi.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Thompson2016_mst,
  author    = {Thompson, A and Maskery, I and Leach, R K},
  journal   = {Measurement Science and Technology},
  title     = {X-ray computed tomography for additive manufacturing: a review},
  year      = {2016},
  month     = {jun},
  number    = {7},
  pages     = {072001},
  volume    = {27},
  doi       = {10.1088/0957-0233/27/7/072001},
  file      = {:Thompson2016_mst.pdf:PDF},
  publisher = {{IOP} Publishing},
}

@article{VIDAL2005333,
title = {Investigation of artefact sources in synchrotron microtomography via virtual X-ray imaging},
journal = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
volume = {234},
number = {3},
pages = {333-348},
year = {2005},
issn = {0168-583X},
doi = {10.1016/j.nimb.2005.02.003},
author = {F.P. Vidal and J.M. Létang and G. Peix and P. Cloetens},
keywords = {X-ray microtomography, Artefact, Deterministic simulation (ray-tracing), Monte Carlo method, Phase contrast, Modulation transfer function},
abstract = {Qualitative and quantitative use of volumes reconstructed by computed tomography (CT) can be compromised due to artefacts which corrupt the data. This article illustrates a method based on virtual X-ray imaging to investigate sources of artefacts which occur in microtomography using synchrotron radiation. In this phenomenological study, different computer simulation methods based on physical X-ray properties, eventually coupled with experimental data, are used in order to compare artefacts obtained theoretically to those present in a volume acquired experimentally, or to predict them for a particular experimental setup. The article begins with the presentation of a synchrotron microtomographic slice of a reinforced fibre composite acquired at the European Synchrotron Radiation Facility (ESRF) containing streak artefacts. This experimental context is used as the motive throughout the paper to illustrate the investigation of some artefact sources. First, the contribution of direct radiation is compared to the contribution of secondary radiations. Then, the effect of some methodological aspects are detailed, including under-sampling, sample and camera misalignment, sample extending outside of the field of view and photonic noise. The effect of harmonic components present in the experimental spectrum are also simulated. Afterwards, detector properties, such as its impulse response or defective pixels, are taken into account. Finally, the importance of phase contrast effects is evaluated. In the last section, this investigation is discussed by putting emphasis on the experimental context which is used throughout this paper.}
}

@inproceedings{Vidal2009TPCG,
  author = {F. P. Vidal and M. Garnier and N. Freud and J. M. L\'etang and N. W. John},
  title = {Simulation of {X-ray} Attenuation on the {GPU}},
  booktitle = {Proceedings of Theory and Practice of Computer Graphics 2009},
  year = 2009,
  pages = {25-32},
  month = jun,
  address = {Cardiff, UK},
  annotation = {Jun~17--19, 2009},
  doi = {10.2312/LocalChapterEvents/TPCG/TPCG09/025-032},
  abstract = {In this paper, we propose to take advantage of computer graphics hardware
	to achieve an accelerated simulation of X-ray transmission imaging,
	and we compare results with a fast and robust software-only implementation.
	The running times of the GPU and CPU implementations are compared
	in different test cases. The results show that the GPU implementation
	with full floating point precision is faster by a factor of about
	60 to 65 than the CPU implementation, without any significant loss
	of accuracy. The increase in performance achieved with GPU calculations
	opens up new perspectives. Notably, it paves the way for physically-realistic
	simulation of X-ray imaging in interactive time.},
  keywords = {Physically based modeling, Raytracing, Physics},
  publisher = {Eurographics Association},
  pdf = {./pdf/Vidal2009TPCG.pdf}
}

@inproceedings{Vidal2010EGPoster,
  author = {F. P. Vidal and M. Garnier and N. Freud and J. M. L\'etang and N. W. John},
  title = {Accelerated Deterministic Simulation of X-ray Attenuation Using Graphics Hardware},
  booktitle = {Eurographics 2010 - Poster},
  year = 2010,
  pages = {Poster 5011},
  month = may,
  address = {Norrk"{o}ping, Sweden},
  annotation = {May~3--7, 2010},
  abstract = {In this paper, we propose a deterministic simulation of X-ray transmission imaging on graphics hardware. Only
	the directly transmitted photons are simulated, using the Beer-Lambert law. Our previous attempt to simulate Xray
	attenuation from polygon meshes utilising the GPU showed significant increase of performance, with respect
	to a validated software implementation, without loss of accuracy. However, the simulations were restricted to
	monochromatic X-rays and finite point sources. We present here an extension to our method to perform physically
	more realistic simulations by taking into account polychromatic X-rays and focal spots causing blur.},
  keywords = {Three-Dimensional Graphics and Realism; Raytracing; Physical Sciences and Engineering; Physics},
  publisher = {Eurographics Association},
  pdf = {pdf/Vidal2010EGPoster.pdf}
}

@article{doi:10.1063/1.364374,
	author = {Cl{\oe}tens, P. and Pateyron-Salom{\'e}, M. and Buffi{\`e}re, J. Y. and Peix, G. and Baruchel, J. and Peyrin, F. and Schlenker, M.},
	doi = {10.1063/1.364374},
	journal = {Journal of Applied Physics},
	number = {9},
	pages = {5878--5886},
	title = {Observation of microstructure and damage in materials by phase sensitive radiography and tomography},
	volume = {81},
	year = {1997}
}

@ARTICLE{8943397,
  author={Hehn, Lorenz and Gradl, Regine and Dierolf, Martin and Morgan, Kaye S. and Paganin, David M. and Pfeiffer, Franz},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Model-Based Iterative Reconstruction for Propagation-Based Phase-Contrast X-Ray {CT} including Models for the Source and the Detector}, 
  year={2020},
  volume={39},
  number={6},
  pages={1975-1987},
  doi={10.1109/TMI.2019.2962615}}


@techreport{osti_6016002,
title = {{XCOM}: Photon cross sections on a personal computer},
author = {Berger, M J and Hubbell, J H},
abstract = {A computer program and data base are presented which can be used to calculate, with a personal computer, photon cross sections for scattering, photoelectric absorption and pair production, as well as total attenuation coefficients, in any element, compound or mixture, at energies from 1 keV to 100 GeV.},
url = {https://doi.org/10.2172/6016002},
place = {United States},
year = {1987},
month = {7},
institution = {National Institute of Standards and Technology}
} 

@webpage{XCOM,
    author = {M. J. Berger and J. H. Hubbell and S. M. Seltzer and J. Chang and J. S. Coursey and R. Sukumar and D. S. Zucker and K. Olsen},
    title = {{XCOM}: Photon cross section database},
    year =1998,
    month = mar,
    url={https://www.physics.nist.gov/PhysRefData/Xcom/html/xcom1.html},
}

@article{repository,
    author = {Vidal, Franck P. and Mitchell, Iwan T. and L\'etang, Jean Michel},
    title = {Supplementary Material: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    journal = {Mendeley Data},
    year =2021,
    month = aug,
    doi = {10.17632/r8b5mcrj6j.1}
}

@webpage{10.5281/zenodo.5075298,
    author = {Franck P. Vidal},
    title = {{gVirtualXRay:} source code of the Virtual X-Ray Imaging Library on {GPU}},
    url={https://doi.org/10.5281/zenodo.5075298},
    year =2021,
    month = aug,
    doi = {10.5281/zenodo.5075298}
}

@webpage{10.5281/zenodo.5075378,
    author = {Franck P. Vidal and Iwan T. Mitchell and Jean M. L\'etang},
    title = {Supplementary material: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    url={https://www.doi.org/10.5281/zenodo.5075378},
    year =2021,
    month = aug,
    doi = {10.5281/zenodo.5075378}
}

@webpage{CT2CAD-Fibres-GitHub,
    author = {Franck P. Vidal and Iwan T. Mitchell and Jean M. L\'etang},
    title = {{GitHub} repository: Use of fast realistic simulations on {GPU} to extract {CAD} models from microtomographic data in the presence of strong {CT} artefacts},
    url={https://github.com/effepivi/CT2CAD-Fibres},
    year =2021,
    month = aug,
}

@webpage{gVirtualXRay,
    author = {Franck P. Vidal},
    title = {{gVirtualXRay}},
    url={http://gvirtualxray.sourceforge.net/},
    year =2021,
    month = aug,
}

@article{doi:10.1080/10255842.2012.670855,
    author = {Francisco P.M. Oliveira and João Manuel R.S. Tavares},
    title = {Medical image registration: a review},
    journal = {Computer Methods in Biomechanics and Biomedical Engineering},
    volume = {17},
    number = {2},
    pages = {73-93},
    year  = {2014},
    publisher = {Taylor & Francis},
    doi = {10.1080/10255842.2012.670855},
    note ={PMID: 22435355},
}

@InProceedings{10.1007/978-3-030-72699-7_29,
author="Wen, Tianci
and Mihail, Radu P.
and Vidal, Franck P.",
editor="Castillo, Pedro A.
and Jim{\'e}nez Laredo, Juan Luis",
title="3D-2D Registration Using X-Ray Simulation and CMA-ES",
booktitle="Applications of Evolutionary Computation",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="453--468",
abstract="Radiographs of the hand are useful in diagnosing and staging diseases such as rheumatoid arthritis (RA) and other musculoskeletal diseases. Radiographs are projections of the 3D anatomy, with the useful information such as pose and pathology becoming lost in the process. We propose a 3D hand pose recovery method for radiographs of hands using a novel hybrid image registration method. Our pose recovery pipeline consists of aligning a simulated X-ray (digitally reconstructed radiograph) of an articulated phantom mesh model to a real hand radiograph using Covariance Matrix Adaptation Evolution Strategy. Early results demonstrate that our approach works well. Further inquiry is required to evaluate the applicability of our registration approach to other articulated musculoskeletal anatomy.",
isbn="978-3-030-72699-7"
}

@inproceedings {vc.20191265,
booktitle = {Computer Graphics and Visual Computing (CGVC)},
editor = {Vidal, Franck P. and Tam, Gary K. L. and Roberts, Jonathan C.},
title = {{Registration of 3D Triangular Models to 2D X-ray Projections Using Black-box Optimisation and X-ray Simulation}},
author = {Wen, Tianci and Mihail, Radu and Al-maliki, shatha and Letang, Jean and Vidal, Franck},
year = {2019},
publisher = {The Eurographics Association},
ISBN = {978-3-03868-096-3},
DOI = {10.2312/cgvc.20191265},
pages = {105-113}
}


@article{ALLISON2016186,
title = {Recent developments in {G}eant4},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {835},
pages = {186-225},
year = {2016},
issn = {0168-9002},
doi = {10.1016/j.nima.2016.06.125},
author = {J. Allison and K. Amako and J. Apostolakis and P. Arce and M. Asai and T. Aso and E. Bagli and A. Bagulya and S. Banerjee and G. Barrand and B.R. Beck and A.G. Bogdanov and D. Brandt and J.M.C. Brown and H. Burkhardt and Ph. Canal and D. Cano-Ott and S. Chauvie and K. Cho and G.A.P. Cirrone and G. Cooperman and M.A. Cortés-Giraldo and G. Cosmo and G. Cuttone and G. Depaola and L. Desorgher and X. Dong and A. Dotti and V.D. Elvira and G. Folger and Z. Francis and A. Galoyan and L. Garnier and M. Gayer and K.L. Genser and V.M. Grichine and S. Guatelli and P. Guèye and P. Gumplinger and A.S. Howard and I. Hřivnáčová and S. Hwang and S. Incerti and A. Ivanchenko and V.N. Ivanchenko and F.W. Jones and S.Y. Jun and P. Kaitaniemi and N. Karakatsanis and M. Karamitros and M. Kelsey and A. Kimura and T. Koi and H. Kurashige and A. Lechner and S.B. Lee and F. Longo and M. Maire and D. Mancusi and A. Mantero and E. Mendoza and B. Morgan and K. Murakami and T. Nikitina and L. Pandola and P. Paprocki and J. Perl and I. Petrović and M.G. Pia and W. Pokorski and J.M. Quesada and M. Raine and M.A. Reis and A. Ribon and A. {Ristić Fira} and F. Romano and G. Russo and G. Santin and T. Sasaki and D. Sawkey and J.I. Shin and I.I. Strakovsky and A. Taborda and S. Tanaka and B. Tomé and T. Toshito and H.N. Tran and P.R. Truscott and L. Urban and V. Uzhinsky and J.M. Verbeke and M. Verderi and B.L. Wendt and H. Wenzel and D.H. Wright and D.M. Wright and T. Yamashita and J. Yarba and H. Yoshida},
keywords = {High energy physics, Nuclear physics, Radiation, Simulation, Computing},
abstract = {Geant4 is a software toolkit for the simulation of the passage of particles through matter. It is used by a large number of experiments and projects in a variety of application domains, including high energy physics, astrophysics and space science, medical physics and radiation protection. Over the past several years, major changes have been made to the toolkit in order to accommodate the needs of these user communities, and to efficiently exploit the growth of computing power made available by advances in technology. The adaptation of Geant4 to multithreading, advances in physics, detector modeling and visualization, extensions to the toolkit, including biasing and reverse Monte Carlo, and tools for physics and release validation are discussed here.}
}

@article{VIDAL20161,
title = {Development and validation of real-time simulation of X-ray imaging with respiratory motion},
journal = {Computerized Medical Imaging and Graphics},
volume = {49},
pages = {1-15},
year = {2016},
issn = {0895-6111},
doi = {10.1016/j.compmedimag.2015.12.002},
author = {Franck P. Vidal and Pierre-Frédéric Villard},
keywords = {X-ray simulation, Deterministic simulation (ray-tracing), Digitally reconstructed radiograph, Respiration simulation, Medical virtual environment, Imaging guidance, Interventional radiology training},
abstract = {We present a framework that combines evolutionary optimisation, soft tissue modelling and ray tracing on GPU to simultaneously compute the respiratory motion and X-ray imaging in real-time. Our aim is to provide validated building blocks with high fidelity to closely match both the human physiology and the physics of X-rays. A CPU-based set of algorithms is presented to model organ behaviours during respiration. Soft tissue deformation is computed with an extension of the Chain Mail method. Rigid elements move according to kinematic laws. A GPU-based surface rendering method is proposed to compute the X-ray image using the Beer–Lambert law. It is provided as an open-source library. A quantitative validation study is provided to objectively assess the accuracy of both components: (i) the respiration against anatomical data, and (ii) the X-ray against the Beer–Lambert law and the results of Monte Carlo simulations. Our implementation can be used in various applications, such as interactive medical virtual environment to train percutaneous transhepatic cholangiography in interventional radiology, 2D/3D registration, computation of digitally reconstructed radiograph, simulation of 4D sinograms to test tomography reconstruction tools.}
}

@Article{VillarragaGomez2019_pe,
  author    = {Villarraga-G{\'{o}}mez, H and Herazo, E L and Smith, S T},
  journal   = {Precision Engineering},
  title     = {X-ray computed tomography: from medical imaging to dimensional metrology},
  year      = {2019},
  month     = {nov},
  pages     = {544--569},
  volume    = {60},
  doi       = {10.1016/j.precisioneng.2019.06.007},
  file      = {:VillarragaGomez2019_pe.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@ARTICLE{SSIM,
  author={Wang, Z and Bovik, A C and Sheikh, H R  and Simoncelli, E P},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  doi={10.1109/TIP.2003.819861}
}
